This file is a merged representation of a subset of the codebase, containing files not matching ignore patterns, combined into a single document by Repomix.

<file_summary>
This section contains a summary of this file.

<purpose>
This file contains a packed representation of the entire repository's contents.
It is designed to be easily consumable by AI systems for analysis, code review,
or other automated processes.
</purpose>

<file_format>
The content is organized as follows:
1. This summary section
2. Repository information
3. Directory structure
4. Repository files (if enabled)
4. Repository files, each consisting of:
  - File path as an attribute
  - Full contents of the file
</file_format>

<usage_guidelines>
- This file should be treated as read-only. Any changes should be made to the
  original repository files, not this packed version.
- When processing this file, use the file path to distinguish
  between different files in the repository.
- Be aware that this file may contain sensitive information. Handle it with
  the same level of security as you would the original repository.
</usage_guidelines>

<notes>
- Some files may have been excluded based on .gitignore rules and Repomix's configuration
- Binary files are not included in this packed representation. Please refer to the Repository Structure section for a complete list of file paths, including binary files
- Files matching these patterns are excluded: varia, .specstory
- Files matching patterns in .gitignore are excluded
- Files matching default ignore patterns are excluded
- Files are sorted by Git change count (files with more changes are at the bottom)
</notes>

<additional_info>

</additional_info>

</file_summary>

<directory_structure>
.claude/
  settings.local.json
.github/
  workflows/
    push.yml
    release.yml
src/
  pyxplod/
    __init__.py
    __main__.py
    pyxplod.py
src-dirs/
  pyxplod/
    __init__/
      __init__.py
    __main__/
      __init__.py
    __version__/
      __init__.py
    pyxplod/
      __init__.py
      analyze_name_usage.py
      create_import_statement.py
      extract_imports.py
      filter_imports_for_names.py
      find_definitions.py
      find_python_files.py
      generate_filename.py
      main.py
      process_python_file_dirs.py
      process_python_file.py
      to_snake_case.py
      validate_paths.py
      write_extracted_file.py
src-files/
  pyxplod/
    __init__.py
    __main__.py
    pyxplod_analyze_name_usage.py
    pyxplod_create_import_statement.py
    pyxplod_extract_imports.py
    pyxplod_filter_imports_for_names.py
    pyxplod_find_definitions.py
    pyxplod_find_python_files.py
    pyxplod_generate_filename.py
    pyxplod_main.py
    pyxplod_process_python_file_dirs.py
    pyxplod_process_python_file.py
    pyxplod_to_snake_case.py
    pyxplod_validate_paths.py
    pyxplod_write_extracted_file.py
    pyxplod.py
tests/
  test_package.py
  test_pyxplod.py
.cursorindexingignore
.cursorrules
.gitignore
.pre-commit-config.yaml
AGENT.md
CHANGELOG.md
CLAUDE.md
LICENSE
package.toml
PLAN.md
pyproject.toml
README.md
test_unicode.py
TODO.md
</directory_structure>

<files>
This section contains the contents of the repository's files.

<file path="src/pyxplod/__main__.py">
# this_file: src/pyxplod/__main__.py
"""Entry point for running pyxplod as a module."""

import fire

from pyxplod.pyxplod import main


if __name__ == "__main__":
    fire.Fire(main)
</file>

<file path="src-dirs/pyxplod/__init__/__init__.py">
# this_file: src/pyxplod/__init__.py
"""pyxplod: Python code exploder - extracts classes and functions into separate files."""

from pyxplod.__version__ import __version__
from pyxplod.pyxplod import main

__all__ = ["__version__", "main"]
</file>

<file path="src-dirs/pyxplod/__main__/__init__.py">
# this_file: src/pyxplod/__main__.py
"""Entry point for running pyxplod as a module."""

import fire

from pyxplod.pyxplod import main


if __name__ == "__main__":
    fire.Fire(main)
</file>

<file path="src-dirs/pyxplod/__version__/__init__.py">
# file generated by setuptools-scm
# don't change, don't track in version control

__all__ = ["__version__", "__version_tuple__", "version", "version_tuple"]

TYPE_CHECKING = False
if TYPE_CHECKING:
    from typing import Tuple
    from typing import Union

    VERSION_TUPLE = Tuple[Union[int, str], ...]
else:
    VERSION_TUPLE = object

version: str
__version__: str
__version_tuple__: VERSION_TUPLE
version_tuple: VERSION_TUPLE

__version__ = version = '0.1.dev3+g123814f.d20250525'
__version_tuple__ = version_tuple = (0, 1, 'dev3', 'g123814f.d20250525')
</file>

<file path="src-dirs/pyxplod/pyxplod/__init__.py">
import ast
import re
import shutil
from pathlib import Path
from typing import Any, Dict, List, Optional, Tuple
from loguru import logger
from rich.console import Console
from rich.progress import BarColumn, Progress, SpinnerColumn, TextColumn
from .to_snake_case import to_snake_case
from .extract_imports import extract_imports
from .analyze_name_usage import analyze_name_usage
from .filter_imports_for_names import filter_imports_for_names
from .find_definitions import find_definitions
from .generate_filename import generate_filename
from .create_import_statement import create_import_statement
from .write_extracted_file import write_extracted_file
from .process_python_file import process_python_file
from .process_python_file_dirs import process_python_file_dirs
from .find_python_files import find_python_files
from .validate_paths import validate_paths
from .main import main
'pyxplod: Python code exploder - extracts classes and functions into separate files.\n\nThis tool takes a Python project and "explodes" it by extracting each class and function\ndefinition into its own file, replacing the original definitions with imports.\n'
console = Console()
</file>

<file path="src-dirs/pyxplod/pyxplod/analyze_name_usage.py">
import ast

def analyze_name_usage(node: ast.AST) -> set[str]:
    """Analyze which names are used in an AST node.

    Returns a set of all names referenced in the node, including decorators.
    """
    names = set()

    class NameCollector(ast.NodeVisitor):

        def visit_Name(self, node: ast.Name) -> None:
            names.add(node.id)
            self.generic_visit(node)

        def visit_Attribute(self, node: ast.Attribute) -> None:
            if isinstance(node.value, ast.Name):
                names.add(node.value.id)
            self.generic_visit(node)
    if hasattr(node, 'decorator_list'):
        for decorator in node.decorator_list:
            if isinstance(decorator, ast.Name):
                names.add(decorator.id)
            elif isinstance(decorator, ast.Attribute) and isinstance(decorator.value, ast.Name):
                names.add(decorator.value.id)
            NameCollector().visit(decorator)
    NameCollector().visit(node)
    return names
</file>

<file path="src-dirs/pyxplod/pyxplod/create_import_statement.py">
import ast

def create_import_statement(module_path: str, name: str) -> ast.ImportFrom:
    """Create an import statement for the extracted definition."""
    return ast.ImportFrom(module=module_path, names=[ast.alias(name=name, asname=None)], level=0)
</file>

<file path="src-dirs/pyxplod/pyxplod/extract_imports.py">
import ast

def extract_imports(tree: ast.AST) -> list[ast.stmt]:
    """Extract all import statements from an AST.

    Returns a list of Import and ImportFrom nodes at module level only.
    """
    imports = []
    for node in tree.body:
        if isinstance(node, ast.Import | ast.ImportFrom):
            imports.append(node)
    return imports
</file>

<file path="src-dirs/pyxplod/pyxplod/filter_imports_for_names.py">
import ast

def filter_imports_for_names(imports: list[ast.stmt], used_names: set[str]) -> list[ast.stmt]:
    """Filter imports to only include those that are used.

    Args:
        imports: List of import statements
        used_names: Set of names used in the code

    Returns:
        List of imports that are actually used
    """
    needed_imports = []
    for imp in imports:
        if isinstance(imp, ast.Import):
            needed_aliases = []
            for alias in imp.names:
                name_in_code = alias.asname if alias.asname else alias.name
                base_name = name_in_code.split('.')[0]
                if base_name in used_names:
                    needed_aliases.append(alias)
            if needed_aliases:
                new_import = ast.Import(names=needed_aliases)
                ast.copy_location(new_import, imp)
                needed_imports.append(new_import)
        elif isinstance(imp, ast.ImportFrom):
            needed_aliases = []
            for alias in imp.names:
                name_in_code = alias.asname if alias.asname else alias.name
                if name_in_code in used_names:
                    needed_aliases.append(alias)
            if needed_aliases:
                new_import = ast.ImportFrom(module=imp.module, names=needed_aliases, level=imp.level)
                ast.copy_location(new_import, imp)
                needed_imports.append(new_import)
    return needed_imports
</file>

<file path="src-dirs/pyxplod/pyxplod/find_definitions.py">
import ast

def find_definitions(tree: ast.AST) -> list[tuple[ast.stmt, str, str]]:
    """Find all class and function definitions at module level.

    Returns list of tuples: (node, type, name) where type is 'class' or 'function'.
    """
    definitions = []
    for node in tree.body:
        if isinstance(node, ast.ClassDef):
            definitions.append((node, 'class', node.name))
        elif isinstance(node, ast.FunctionDef):
            definitions.append((node, 'function', node.name))
    return definitions
</file>

<file path="src-dirs/pyxplod/pyxplod/find_python_files.py">
from pathlib import Path

def find_python_files(directory: Path) -> list[Path]:
    """Recursively find all Python files in a directory."""
    python_files = []
    for file in directory.rglob('*.py'):
        if '__pycache__' not in str(file) and '.pyc' not in str(file):
            python_files.append(file)
    return sorted(python_files)
</file>

<file path="src-dirs/pyxplod/pyxplod/generate_filename.py">
def generate_filename(base_name: str, def_name: str, def_type: str, existing_files: set) -> str:
    """Generate a unique filename for the extracted definition.

    Handles deduplication by appending numbers if necessary.
    """
    snake_name = to_snake_case(def_name)
    filename = f'{base_name}_{snake_name}.py'
    if filename in existing_files:
        counter = 2
        while f'{base_name}_{snake_name}_{counter}.py' in existing_files:
            counter += 1
        filename = f'{base_name}_{snake_name}_{counter}.py'
    existing_files.add(filename)
    return filename
</file>

<file path="src-dirs/pyxplod/pyxplod/main.py">
from pathlib import Path
from loguru import logger
from rich.progress import BarColumn, Progress, SpinnerColumn, TextColumn

def main(input: str, output: str, method: str='files', verbose: bool=False) -> None:
    """Explode a Python project by extracting classes and functions into separate files.

    Args:
        input: Path to the input directory containing Python files
        output: Path to the output directory where exploded files will be created
        method: Explosion method - 'files' (default) or 'dirs'
        verbose: Enable verbose logging for debugging
    """
    if method not in ['files', 'dirs']:
        logger.error(f"Invalid method '{method}'. Must be 'files' or 'dirs'.")
        return
    if verbose:
        logger.remove()
        logger.add(console.print, format='{time:HH:mm:ss} | {level} | {message}', level='DEBUG')
    else:
        logger.remove()
        logger.add(console.print, format='{message}', level='INFO')
    input_path = Path(input).resolve()
    output_path = Path(output).resolve()
    if not validate_paths(input_path, output_path):
        return
    python_files = find_python_files(input_path)
    if not python_files:
        logger.warning(f'No Python files found in {input_path}')
        return
    logger.info(f'Found {len(python_files)} Python files to process')
    output_path.mkdir(parents=True, exist_ok=True)
    with Progress(SpinnerColumn(), TextColumn('[progress.description]{task.description}'), BarColumn(), TextColumn('[progress.percentage]{task.percentage:>3.0f}%'), console=console) as progress:
        task = progress.add_task('Processing files...', total=len(python_files))
        for py_file in python_files:
            try:
                if method == 'files':
                    process_python_file(py_file, output_path, input_path)
                else:
                    process_python_file_dirs(py_file, output_path, input_path)
                progress.update(task, advance=1)
            except Exception as e:
                logger.error(f'Failed to process {py_file}: {e}')
                if verbose:
                    logger.exception('Detailed error:')
    logger.info(f"‚ú® Successfully exploded {len(python_files)} files to {output_path} using method '{method}'")
</file>

<file path="src-dirs/pyxplod/pyxplod/process_python_file_dirs.py">
import ast
from pathlib import Path
from loguru import logger

def process_python_file_dirs(input_file: Path, output_base: Path, input_root: Path) -> None:
    """Process a single Python file using the 'dirs' method.

    Creates a directory for each .py file and extracts definitions into separate files
    within that directory, with an __init__.py containing imports and module-level code.
    """
    logger.info(f'Processing (dirs): {input_file}')
    relative_path = input_file.relative_to(input_root)
    dir_name = relative_path.stem
    output_dir = output_base / relative_path.parent / dir_name
    output_dir.mkdir(parents=True, exist_ok=True)
    try:
        content = input_file.read_text(encoding='utf-8')
        tree = ast.parse(content, filename=str(input_file))
    except SyntaxError as e:
        logger.error(f'Syntax error in {input_file}: {e}')
        return
    except Exception as e:
        logger.error(f'Error reading {input_file}: {e}')
        return
    imports = extract_imports(tree)
    definitions = find_definitions(tree)
    if not definitions:
        init_file = output_dir / '__init__.py'
        init_file.write_text(content, encoding='utf-8')
        logger.debug(f'No definitions found, created __init__.py: {input_file}')
        return
    existing_files = set()
    new_imports = []
    remaining_body = []
    for node in tree.body:
        is_definition = False
        for def_node, def_type, def_name in definitions:
            if node is def_node:
                is_definition = True
                snake_name = to_snake_case(def_name)
                filename = f'{snake_name}.py'
                if filename in existing_files:
                    counter = 2
                    while f'{snake_name}_{counter}.py' in existing_files:
                        counter += 1
                    filename = f'{snake_name}_{counter}.py'
                existing_files.add(filename)
                extracted_path = output_dir / filename
                write_extracted_file(extracted_path, imports.copy(), def_node)
                import_stmt = create_import_statement(f'.{filename[:-3]}', def_name)
                new_imports.append(import_stmt)
                break
        if not is_definition and node not in imports:
            remaining_body.append(node)
    init_tree = ast.Module(body=imports + new_imports + remaining_body, type_ignores=tree.type_ignores)
    init_file = output_dir / '__init__.py'
    init_file.write_text(ast.unparse(init_tree), encoding='utf-8')
    logger.info(f'Created package: {output_dir}')
    logger.debug(f'Extracted {len(definitions)} definitions from {input_file}')
</file>

<file path="src-dirs/pyxplod/pyxplod/process_python_file.py">
import ast
from pathlib import Path
from loguru import logger

def process_python_file(input_file: Path, output_base: Path, input_root: Path) -> None:
    """Process a single Python file, extracting definitions and creating new files."""
    logger.info(f'Processing: {input_file}')
    relative_path = input_file.relative_to(input_root)
    output_dir = output_base / relative_path.parent
    output_dir.mkdir(parents=True, exist_ok=True)
    try:
        content = input_file.read_text(encoding='utf-8')
        tree = ast.parse(content, filename=str(input_file))
    except SyntaxError as e:
        logger.error(f'Syntax error in {input_file}: {e}')
        return
    except Exception as e:
        logger.error(f'Error reading {input_file}: {e}')
        return
    imports = extract_imports(tree)
    definitions = find_definitions(tree)
    if not definitions:
        output_file = output_base / relative_path
        output_file.write_text(content, encoding='utf-8')
        logger.debug(f'No definitions found, copied: {input_file}')
        return
    existing_files = set()
    base_name = input_file.stem
    new_imports = []
    remaining_body = []
    for node in tree.body:
        is_definition = False
        for def_node, def_type, def_name in definitions:
            if node is def_node:
                is_definition = True
                filename = generate_filename(base_name, def_name, def_type, existing_files)
                extracted_path = output_dir / filename
                write_extracted_file(extracted_path, imports.copy(), def_node)
                import_stmt = create_import_statement(f'.{filename[:-3]}', def_name)
                new_imports.append(import_stmt)
                break
        if not is_definition and node not in imports:
            remaining_body.append(node)
    modified_tree = ast.Module(body=imports + new_imports + remaining_body, type_ignores=tree.type_ignores)
    output_file = output_base / relative_path
    output_file.write_text(ast.unparse(modified_tree), encoding='utf-8')
    logger.info(f'Modified main file: {output_file}')
    logger.debug(f'Extracted {len(definitions)} definitions from {input_file}')
</file>

<file path="src-dirs/pyxplod/pyxplod/to_snake_case.py">
import re

def to_snake_case(name: str) -> str:
    """Convert a name to snake_case format.

    Handles CamelCase, pascalCase, and already snake_case names.
    """
    s1 = re.sub('(.)([A-Z][a-z]+)', '\\1_\\2', name)
    s2 = re.sub('([a-z0-9])([A-Z])', '\\1_\\2', s1)
    return s2.lower()
</file>

<file path="src-dirs/pyxplod/pyxplod/validate_paths.py">
from pathlib import Path
from loguru import logger

def validate_paths(input_path: Path, output_path: Path) -> bool:
    """Validate input and output paths."""
    if not input_path.exists():
        logger.error(f'Input path does not exist: {input_path}')
        return False
    if not input_path.is_dir():
        logger.error(f'Input path is not a directory: {input_path}')
        return False
    if output_path.exists() and (not output_path.is_dir()):
        logger.error(f'Output path exists but is not a directory: {output_path}')
        return False
    return True
</file>

<file path="src-dirs/pyxplod/pyxplod/write_extracted_file.py">
import ast
from pathlib import Path
from loguru import logger

def write_extracted_file(output_path: Path, imports: list[ast.stmt], definition: ast.stmt) -> None:
    """Write the extracted definition to a new file with necessary imports."""
    used_names = analyze_name_usage(definition)
    filtered_imports = filter_imports_for_names(imports, used_names)
    new_module = ast.Module(body=[*filtered_imports, definition], type_ignores=[])
    code = ast.unparse(new_module)
    output_path.parent.mkdir(parents=True, exist_ok=True)
    output_path.write_text(code, encoding='utf-8')
    logger.debug(f'Created file: {output_path} with {len(filtered_imports)} imports (filtered from {len(imports)})')
</file>

<file path="src-files/pyxplod/__init__.py">
# this_file: src/pyxplod/__init__.py
"""pyxplod: Python code exploder - extracts classes and functions into separate files."""

from pyxplod.__version__ import __version__
from pyxplod.pyxplod import main

__all__ = ["__version__", "main"]
</file>

<file path="src-files/pyxplod/__main__.py">
# this_file: src/pyxplod/__main__.py
"""Entry point for running pyxplod as a module."""

import fire

from pyxplod.pyxplod import main


if __name__ == "__main__":
    fire.Fire(main)
</file>

<file path="src-files/pyxplod/pyxplod_analyze_name_usage.py">
import ast

def analyze_name_usage(node: ast.AST) -> set[str]:
    """Analyze which names are used in an AST node.

    Returns a set of all names referenced in the node, including decorators.
    """
    names = set()

    class NameCollector(ast.NodeVisitor):

        def visit_Name(self, node: ast.Name) -> None:
            names.add(node.id)
            self.generic_visit(node)

        def visit_Attribute(self, node: ast.Attribute) -> None:
            if isinstance(node.value, ast.Name):
                names.add(node.value.id)
            self.generic_visit(node)
    if hasattr(node, 'decorator_list'):
        for decorator in node.decorator_list:
            if isinstance(decorator, ast.Name):
                names.add(decorator.id)
            elif isinstance(decorator, ast.Attribute) and isinstance(decorator.value, ast.Name):
                names.add(decorator.value.id)
            NameCollector().visit(decorator)
    NameCollector().visit(node)
    return names
</file>

<file path="src-files/pyxplod/pyxplod_create_import_statement.py">
import ast

def create_import_statement(module_path: str, name: str) -> ast.ImportFrom:
    """Create an import statement for the extracted definition."""
    return ast.ImportFrom(module=module_path, names=[ast.alias(name=name, asname=None)], level=0)
</file>

<file path="src-files/pyxplod/pyxplod_extract_imports.py">
import ast

def extract_imports(tree: ast.AST) -> list[ast.stmt]:
    """Extract all import statements from an AST.

    Returns a list of Import and ImportFrom nodes at module level only.
    """
    imports = []
    for node in tree.body:
        if isinstance(node, ast.Import | ast.ImportFrom):
            imports.append(node)
    return imports
</file>

<file path="src-files/pyxplod/pyxplod_filter_imports_for_names.py">
import ast

def filter_imports_for_names(imports: list[ast.stmt], used_names: set[str]) -> list[ast.stmt]:
    """Filter imports to only include those that are used.

    Args:
        imports: List of import statements
        used_names: Set of names used in the code

    Returns:
        List of imports that are actually used
    """
    needed_imports = []
    for imp in imports:
        if isinstance(imp, ast.Import):
            needed_aliases = []
            for alias in imp.names:
                name_in_code = alias.asname if alias.asname else alias.name
                base_name = name_in_code.split('.')[0]
                if base_name in used_names:
                    needed_aliases.append(alias)
            if needed_aliases:
                new_import = ast.Import(names=needed_aliases)
                ast.copy_location(new_import, imp)
                needed_imports.append(new_import)
        elif isinstance(imp, ast.ImportFrom):
            needed_aliases = []
            for alias in imp.names:
                name_in_code = alias.asname if alias.asname else alias.name
                if name_in_code in used_names:
                    needed_aliases.append(alias)
            if needed_aliases:
                new_import = ast.ImportFrom(module=imp.module, names=needed_aliases, level=imp.level)
                ast.copy_location(new_import, imp)
                needed_imports.append(new_import)
    return needed_imports
</file>

<file path="src-files/pyxplod/pyxplod_find_definitions.py">
import ast

def find_definitions(tree: ast.AST) -> list[tuple[ast.stmt, str, str]]:
    """Find all class and function definitions at module level.

    Returns list of tuples: (node, type, name) where type is 'class' or 'function'.
    """
    definitions = []
    for node in tree.body:
        if isinstance(node, ast.ClassDef):
            definitions.append((node, 'class', node.name))
        elif isinstance(node, ast.FunctionDef):
            definitions.append((node, 'function', node.name))
    return definitions
</file>

<file path="src-files/pyxplod/pyxplod_find_python_files.py">
from pathlib import Path

def find_python_files(directory: Path) -> list[Path]:
    """Recursively find all Python files in a directory."""
    python_files = []
    for file in directory.rglob('*.py'):
        if '__pycache__' not in str(file) and '.pyc' not in str(file):
            python_files.append(file)
    return sorted(python_files)
</file>

<file path="src-files/pyxplod/pyxplod_generate_filename.py">
def generate_filename(base_name: str, def_name: str, def_type: str, existing_files: set) -> str:
    """Generate a unique filename for the extracted definition.

    Handles deduplication by appending numbers if necessary.
    """
    snake_name = to_snake_case(def_name)
    filename = f'{base_name}_{snake_name}.py'
    if filename in existing_files:
        counter = 2
        while f'{base_name}_{snake_name}_{counter}.py' in existing_files:
            counter += 1
        filename = f'{base_name}_{snake_name}_{counter}.py'
    existing_files.add(filename)
    return filename
</file>

<file path="src-files/pyxplod/pyxplod_main.py">
from pathlib import Path
from loguru import logger
from rich.progress import BarColumn, Progress, SpinnerColumn, TextColumn

def main(input: str, output: str, method: str='files', verbose: bool=False) -> None:
    """Explode a Python project by extracting classes and functions into separate files.

    Args:
        input: Path to the input directory containing Python files
        output: Path to the output directory where exploded files will be created
        method: Explosion method - 'files' (default) or 'dirs'
        verbose: Enable verbose logging for debugging
    """
    if method not in ['files', 'dirs']:
        logger.error(f"Invalid method '{method}'. Must be 'files' or 'dirs'.")
        return
    if verbose:
        logger.remove()
        logger.add(console.print, format='{time:HH:mm:ss} | {level} | {message}', level='DEBUG')
    else:
        logger.remove()
        logger.add(console.print, format='{message}', level='INFO')
    input_path = Path(input).resolve()
    output_path = Path(output).resolve()
    if not validate_paths(input_path, output_path):
        return
    python_files = find_python_files(input_path)
    if not python_files:
        logger.warning(f'No Python files found in {input_path}')
        return
    logger.info(f'Found {len(python_files)} Python files to process')
    output_path.mkdir(parents=True, exist_ok=True)
    with Progress(SpinnerColumn(), TextColumn('[progress.description]{task.description}'), BarColumn(), TextColumn('[progress.percentage]{task.percentage:>3.0f}%'), console=console) as progress:
        task = progress.add_task('Processing files...', total=len(python_files))
        for py_file in python_files:
            try:
                if method == 'files':
                    process_python_file(py_file, output_path, input_path)
                else:
                    process_python_file_dirs(py_file, output_path, input_path)
                progress.update(task, advance=1)
            except Exception as e:
                logger.error(f'Failed to process {py_file}: {e}')
                if verbose:
                    logger.exception('Detailed error:')
    logger.info(f"‚ú® Successfully exploded {len(python_files)} files to {output_path} using method '{method}'")
</file>

<file path="src-files/pyxplod/pyxplod_process_python_file_dirs.py">
import ast
from pathlib import Path
from loguru import logger

def process_python_file_dirs(input_file: Path, output_base: Path, input_root: Path) -> None:
    """Process a single Python file using the 'dirs' method.

    Creates a directory for each .py file and extracts definitions into separate files
    within that directory, with an __init__.py containing imports and module-level code.
    """
    logger.info(f'Processing (dirs): {input_file}')
    relative_path = input_file.relative_to(input_root)
    dir_name = relative_path.stem
    output_dir = output_base / relative_path.parent / dir_name
    output_dir.mkdir(parents=True, exist_ok=True)
    try:
        content = input_file.read_text(encoding='utf-8')
        tree = ast.parse(content, filename=str(input_file))
    except SyntaxError as e:
        logger.error(f'Syntax error in {input_file}: {e}')
        return
    except Exception as e:
        logger.error(f'Error reading {input_file}: {e}')
        return
    imports = extract_imports(tree)
    definitions = find_definitions(tree)
    if not definitions:
        init_file = output_dir / '__init__.py'
        init_file.write_text(content, encoding='utf-8')
        logger.debug(f'No definitions found, created __init__.py: {input_file}')
        return
    existing_files = set()
    new_imports = []
    remaining_body = []
    for node in tree.body:
        is_definition = False
        for def_node, def_type, def_name in definitions:
            if node is def_node:
                is_definition = True
                snake_name = to_snake_case(def_name)
                filename = f'{snake_name}.py'
                if filename in existing_files:
                    counter = 2
                    while f'{snake_name}_{counter}.py' in existing_files:
                        counter += 1
                    filename = f'{snake_name}_{counter}.py'
                existing_files.add(filename)
                extracted_path = output_dir / filename
                write_extracted_file(extracted_path, imports.copy(), def_node)
                import_stmt = create_import_statement(f'.{filename[:-3]}', def_name)
                new_imports.append(import_stmt)
                break
        if not is_definition and node not in imports:
            remaining_body.append(node)
    init_tree = ast.Module(body=imports + new_imports + remaining_body, type_ignores=tree.type_ignores)
    init_file = output_dir / '__init__.py'
    init_file.write_text(ast.unparse(init_tree), encoding='utf-8')
    logger.info(f'Created package: {output_dir}')
    logger.debug(f'Extracted {len(definitions)} definitions from {input_file}')
</file>

<file path="src-files/pyxplod/pyxplod_process_python_file.py">
import ast
from pathlib import Path
from loguru import logger

def process_python_file(input_file: Path, output_base: Path, input_root: Path) -> None:
    """Process a single Python file, extracting definitions and creating new files."""
    logger.info(f'Processing: {input_file}')
    relative_path = input_file.relative_to(input_root)
    output_dir = output_base / relative_path.parent
    output_dir.mkdir(parents=True, exist_ok=True)
    try:
        content = input_file.read_text(encoding='utf-8')
        tree = ast.parse(content, filename=str(input_file))
    except SyntaxError as e:
        logger.error(f'Syntax error in {input_file}: {e}')
        return
    except Exception as e:
        logger.error(f'Error reading {input_file}: {e}')
        return
    imports = extract_imports(tree)
    definitions = find_definitions(tree)
    if not definitions:
        output_file = output_base / relative_path
        output_file.write_text(content, encoding='utf-8')
        logger.debug(f'No definitions found, copied: {input_file}')
        return
    existing_files = set()
    base_name = input_file.stem
    new_imports = []
    remaining_body = []
    for node in tree.body:
        is_definition = False
        for def_node, def_type, def_name in definitions:
            if node is def_node:
                is_definition = True
                filename = generate_filename(base_name, def_name, def_type, existing_files)
                extracted_path = output_dir / filename
                write_extracted_file(extracted_path, imports.copy(), def_node)
                import_stmt = create_import_statement(f'.{filename[:-3]}', def_name)
                new_imports.append(import_stmt)
                break
        if not is_definition and node not in imports:
            remaining_body.append(node)
    modified_tree = ast.Module(body=imports + new_imports + remaining_body, type_ignores=tree.type_ignores)
    output_file = output_base / relative_path
    output_file.write_text(ast.unparse(modified_tree), encoding='utf-8')
    logger.info(f'Modified main file: {output_file}')
    logger.debug(f'Extracted {len(definitions)} definitions from {input_file}')
</file>

<file path="src-files/pyxplod/pyxplod_to_snake_case.py">
import re

def to_snake_case(name: str) -> str:
    """Convert a name to snake_case format.

    Handles CamelCase, pascalCase, and already snake_case names.
    """
    s1 = re.sub('(.)([A-Z][a-z]+)', '\\1_\\2', name)
    s2 = re.sub('([a-z0-9])([A-Z])', '\\1_\\2', s1)
    return s2.lower()
</file>

<file path="src-files/pyxplod/pyxplod_validate_paths.py">
from pathlib import Path
from loguru import logger

def validate_paths(input_path: Path, output_path: Path) -> bool:
    """Validate input and output paths."""
    if not input_path.exists():
        logger.error(f'Input path does not exist: {input_path}')
        return False
    if not input_path.is_dir():
        logger.error(f'Input path is not a directory: {input_path}')
        return False
    if output_path.exists() and (not output_path.is_dir()):
        logger.error(f'Output path exists but is not a directory: {output_path}')
        return False
    return True
</file>

<file path="src-files/pyxplod/pyxplod_write_extracted_file.py">
import ast
from pathlib import Path
from loguru import logger

def write_extracted_file(output_path: Path, imports: list[ast.stmt], definition: ast.stmt) -> None:
    """Write the extracted definition to a new file with necessary imports."""
    used_names = analyze_name_usage(definition)
    filtered_imports = filter_imports_for_names(imports, used_names)
    new_module = ast.Module(body=[*filtered_imports, definition], type_ignores=[])
    code = ast.unparse(new_module)
    output_path.parent.mkdir(parents=True, exist_ok=True)
    output_path.write_text(code, encoding='utf-8')
    logger.debug(f'Created file: {output_path} with {len(filtered_imports)} imports (filtered from {len(imports)})')
</file>

<file path="src-files/pyxplod/pyxplod.py">
import ast
import re
import shutil
from pathlib import Path
from typing import Any, Dict, List, Optional, Tuple
from loguru import logger
from rich.console import Console
from rich.progress import BarColumn, Progress, SpinnerColumn, TextColumn
from .pyxplod_to_snake_case import to_snake_case
from .pyxplod_extract_imports import extract_imports
from .pyxplod_analyze_name_usage import analyze_name_usage
from .pyxplod_filter_imports_for_names import filter_imports_for_names
from .pyxplod_find_definitions import find_definitions
from .pyxplod_generate_filename import generate_filename
from .pyxplod_create_import_statement import create_import_statement
from .pyxplod_write_extracted_file import write_extracted_file
from .pyxplod_process_python_file import process_python_file
from .pyxplod_process_python_file_dirs import process_python_file_dirs
from .pyxplod_find_python_files import find_python_files
from .pyxplod_validate_paths import validate_paths
from .pyxplod_main import main
'pyxplod: Python code exploder - extracts classes and functions into separate files.\n\nThis tool takes a Python project and "explodes" it by extracting each class and function\ndefinition into its own file, replacing the original definitions with imports.\n'
console = Console()
</file>

<file path="test_unicode.py">
#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""Test Unicode support with various characters."""

def greet_world():
    """Say hello in multiple languages."""
    return {
        'english': 'Hello',
        'spanish': 'Hola',
        'french': 'Bonjour',
        'german': 'Gr√º√üe',
        'japanese': '„Åì„Çì„Å´„Å°„ÅØ',
        'chinese': '‰Ω†Â•Ω',
        'arabic': 'ŸÖÿ±ÿ≠ÿ®ÿß',
        'russian': '–ü—Ä–∏–≤–µ—Ç',
        'emoji': 'üëãüåç'
    }

class UnicodeHandler:
    """Handle Unicode text with special characters: √°√©√≠√≥√∫ √± √ß √∏."""
    
    def process(self, text: str) -> str:
        """Process text with Unicode: ‚Üí ‚Üê ‚Üë ‚Üì ‚Ä¢ ¬© ¬Æ ‚Ñ¢."""
        return f"Processed: {text}"

# Test mathematical symbols: ‚àë ‚àè ‚à´ ‚àö ‚àû ‚âà ‚â† ‚â§ ‚â•
MATH_PI = "œÄ ‚âà 3.14159"
</file>

<file path=".claude/settings.local.json">
{
  "permissions": {
    "allow": [
      "Bash(python -m pytest tests/ -v)",
      "Bash(uv pip install:*)",
      "Bash(python -m pytest tests/test_pyxplod.py -v)",
      "Bash(python -m pytest tests/test_pyxplod.py::TestProcessing::test_process_simple_file -xvs)",
      "Bash(python -m pytest tests/ -v --tb=short)",
      "Bash(black:*)",
      "Bash(pyxplod:*)",
      "Bash(python:*)",
      "Bash(rm:*)",
      "Bash(tree:*)",
      "Bash(cat:*)",
      "Bash(echo:*)",
      "Bash(find:*)",
      "Bash(mkdir:*)",
      "Bash(ls:*)",
      "Bash(grep:*)",
      "Bash(rg:*)"
    ],
    "deny": []
  }
}
</file>

<file path=".github/workflows/push.yml">
name: Build & Test

on:
  push:
    branches: [main]
    tags-ignore: ["v*"]
  pull_request:
    branches: [main]
  workflow_dispatch:

permissions:
  contents: write
  id-token: write

concurrency:
  group: ${{ github.workflow }}-${{ github.ref }}
  cancel-in-progress: true

jobs:
  quality:
    name: Code Quality
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Run Ruff lint
        uses: astral-sh/ruff-action@v3
        with:
          version: "latest"
          args: "check --output-format=github"

      - name: Run Ruff Format
        uses: astral-sh/ruff-action@v3
        with:
          version: "latest"
          args: "format --check --respect-gitignore"

  test:
    name: Run Tests
    needs: quality
    strategy:
      matrix:
        python-version: ["3.10", "3.11", "3.12"]
        os: [ubuntu-latest]
      fail-fast: true
    runs-on: ${{ matrix.os }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: ${{ matrix.python-version }}

      - name: Install UV
        uses: astral-sh/setup-uv@v5
        with:
          version: "latest"
          python-version: ${{ matrix.python-version }}
          enable-cache: true
          cache-suffix: ${{ matrix.os }}-${{ matrix.python-version }}

      - name: Install test dependencies
        run: |
          uv pip install --system --upgrade pip
          uv pip install --system ".[test]"

      - name: Run tests with Pytest
        run: uv run pytest -n auto --maxfail=1 --disable-warnings --cov-report=xml --cov-config=pyproject.toml --cov=src/pyxplod --cov=tests tests/

      - name: Upload coverage report
        uses: actions/upload-artifact@v4
        with:
          name: coverage-${{ matrix.python-version }}-${{ matrix.os }}
          path: coverage.xml

  build:
    name: Build Distribution
    needs: test
    runs-on: ubuntu-latest
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.12"

      - name: Install UV
        uses: astral-sh/setup-uv@v5
        with:
          version: "latest"
          python-version: "3.12"
          enable-cache: true

      - name: Install build tools
        run: uv pip install build hatchling hatch-vcs

      - name: Build distributions
        run: uv run python -m build --outdir dist

      - name: Upload distribution artifacts
        uses: actions/upload-artifact@v4
        with:
          name: dist-files
          path: dist/
          retention-days: 5
</file>

<file path=".github/workflows/release.yml">
name: Release

on:
  push:
    tags: ["v*"]

permissions:
  contents: write
  id-token: write

jobs:
  release:
    name: Release to PyPI
    runs-on: ubuntu-latest
    environment:
      name: pypi
      url: https://pypi.org/p/pyxplod
    steps:
      - name: Checkout code
        uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.12"

      - name: Install UV
        uses: astral-sh/setup-uv@v5
        with:
          version: "latest"
          python-version: "3.12"
          enable-cache: true

      - name: Install build tools
        run: uv pip install build hatchling hatch-vcs

      - name: Build distributions
        run: uv run python -m build --outdir dist

      - name: Verify distribution files
        run: |
          ls -la dist/
          test -n "$(find dist -name '*.whl')" || (echo "Wheel file missing" && exit 1)
          test -n "$(find dist -name '*.tar.gz')" || (echo "Source distribution missing" && exit 1)

      - name: Publish to PyPI
        uses: pypa/gh-action-pypi-publish@release/v1
        with:
          password: ${{ secrets.PYPI_TOKEN }}

      - name: Create GitHub Release
        uses: softprops/action-gh-release@v1
        with:
          files: dist/*
          generate_release_notes: true
        env:
          GITHUB_TOKEN: ${{ secrets.GITHUB_TOKEN }}
</file>

<file path="src/pyxplod/__init__.py">
# this_file: src/pyxplod/__init__.py
"""pyxplod: Python code exploder - extracts classes and functions into separate files."""

from pyxplod.__version__ import __version__
from pyxplod.pyxplod import main

__all__ = ["__version__", "main"]
</file>

<file path="tests/test_pyxplod.py">
#!/usr/bin/env python3
# this_file: tests/test_pyxplod.py

"""Test suite for pyxplod functionality."""

import ast

from pyxplod.pyxplod import (
    create_import_statement,
    extract_imports,
    find_definitions,
    find_python_files,
    generate_filename,
    process_python_file,
    to_snake_case,
    validate_paths,
)


class TestUtilityFunctions:
    """Test utility functions used in pyxplod."""

    def test_to_snake_case(self):
        """Test conversion of various formats to snake_case."""
        assert to_snake_case("CamelCase") == "camel_case"
        assert to_snake_case("camelCase") == "camel_case"
        assert to_snake_case("snake_case") == "snake_case"
        assert to_snake_case("HTTPResponse") == "http_response"
        assert to_snake_case("getHTTPResponseCode") == "get_http_response_code"
        assert to_snake_case("SimpleTest") == "simple_test"
        assert to_snake_case("a") == "a"
        assert to_snake_case("A") == "a"

    def test_extract_imports(self):
        """Test extraction of import statements from AST."""
        code = """
import os
from pathlib import Path
import sys
from typing import List, Dict

def my_function():
    pass
"""
        tree = ast.parse(code)
        imports = extract_imports(tree)

        assert len(imports) == 4
        assert all(isinstance(imp, ast.Import | ast.ImportFrom) for imp in imports)

    def test_find_definitions(self):
        """Test finding class and function definitions."""
        code = """
import os

class MyClass:
    pass

def my_function():
    pass

class AnotherClass:
    def method(self):
        pass

def another_function():
    return 42

x = 10  # Not a definition
"""
        tree = ast.parse(code)
        definitions = find_definitions(tree)

        assert len(definitions) == 4
        assert definitions[0][1] == "class"
        assert definitions[0][2] == "MyClass"
        assert definitions[1][1] == "function"
        assert definitions[1][2] == "my_function"
        assert definitions[2][1] == "class"
        assert definitions[2][2] == "AnotherClass"
        assert definitions[3][1] == "function"
        assert definitions[3][2] == "another_function"

    def test_generate_filename(self):
        """Test filename generation with deduplication."""
        existing = set()

        # First file
        name1 = generate_filename("module", "MyClass", "class", existing)
        assert name1 == "module_my_class.py"

        # Duplicate should get a number
        name2 = generate_filename("module", "MyClass", "class", existing)
        assert name2 == "module_my_class_2.py"

        # Another duplicate
        name3 = generate_filename("module", "MyClass", "class", existing)
        assert name3 == "module_my_class_3.py"

        # Different name should work normally
        name4 = generate_filename("module", "OtherClass", "class", existing)
        assert name4 == "module_other_class.py"

    def test_create_import_statement(self):
        """Test creation of import statements."""
        import_stmt = create_import_statement(".module_my_class", "MyClass")

        assert isinstance(import_stmt, ast.ImportFrom)
        assert import_stmt.module == ".module_my_class"
        assert import_stmt.level == 0
        assert len(import_stmt.names) == 1
        assert import_stmt.names[0].name == "MyClass"
        assert import_stmt.names[0].asname is None


class TestFileOperations:
    """Test file discovery and validation functions."""

    def test_find_python_files(self, tmp_path):
        """Test recursive Python file discovery."""
        # Create test directory structure
        (tmp_path / "src").mkdir()
        (tmp_path / "src" / "module1.py").write_text("# Python file")
        (tmp_path / "src" / "module2.py").write_text("# Another file")
        (tmp_path / "src" / "subdir").mkdir()
        (tmp_path / "src" / "subdir" / "module3.py").write_text("# Nested file")
        (tmp_path / "src" / "__pycache__").mkdir()
        (tmp_path / "src" / "__pycache__" / "module1.pyc").write_text("# Compiled")
        (tmp_path / "README.md").write_text("# Not a Python file")

        files = find_python_files(tmp_path)

        assert len(files) == 3
        assert all(f.suffix == ".py" for f in files)
        assert all("__pycache__" not in str(f) for f in files)
        assert all(".pyc" not in str(f) for f in files)

    def test_validate_paths(self, tmp_path):
        """Test path validation."""
        # Valid paths
        input_dir = tmp_path / "input"
        input_dir.mkdir()
        output_dir = tmp_path / "output"

        assert validate_paths(input_dir, output_dir) is True

        # Non-existent input
        assert validate_paths(tmp_path / "nonexistent", output_dir) is False

        # Input is file, not directory
        input_file = tmp_path / "file.txt"
        input_file.write_text("content")
        assert validate_paths(input_file, output_dir) is False

        # Output exists but is file
        output_file = tmp_path / "output.txt"
        output_file.write_text("content")
        assert validate_paths(input_dir, output_file) is False


class TestProcessing:
    """Test the main processing functionality."""

    def test_process_simple_file(self, tmp_path):
        """Test processing a simple Python file."""
        # Create input directory and file
        input_dir = tmp_path / "input"
        input_dir.mkdir()

        test_file = input_dir / "test.py"
        test_file.write_text(
            """
import os

class TestClass:
    def method(self):
        return "test"

def test_function():
    return 42

print("Module loaded")
"""
        )

        # Process the file
        output_dir = tmp_path / "output"
        output_dir.mkdir()

        process_python_file(test_file, output_dir, input_dir)

        # Check output files exist
        assert (output_dir / "test.py").exists()
        assert (output_dir / "test_test_class.py").exists()
        assert (output_dir / "test_test_function.py").exists()

        # Check main file content
        main_content = (output_dir / "test.py").read_text()
        assert "import os" in main_content
        assert "from .test_test_class import TestClass" in main_content
        assert "from .test_test_function import test_function" in main_content
        assert (
            "print('Module loaded')" in main_content
            or 'print("Module loaded")' in main_content
        )
        assert "def test_function" not in main_content
        assert "class TestClass" not in main_content

        # Check extracted class file
        class_content = (output_dir / "test_test_class.py").read_text()
        assert "import os" in class_content
        assert "class TestClass:" in class_content
        assert "def method(self):" in class_content

        # Check extracted function file
        func_content = (output_dir / "test_test_function.py").read_text()
        assert "import os" in func_content
        assert "def test_function():" in func_content
        assert "return 42" in func_content

    def test_process_file_no_definitions(self, tmp_path):
        """Test processing a file with no class/function definitions."""
        input_dir = tmp_path / "input"
        input_dir.mkdir()

        test_file = input_dir / "constants.py"
        test_file.write_text(
            """
# Constants file
VERSION = "1.0.0"
DEBUG = True
CONFIG = {"key": "value"}
"""
        )

        output_dir = tmp_path / "output"
        output_dir.mkdir()

        process_python_file(test_file, output_dir, input_dir)

        # Should just copy the file
        assert (output_dir / "constants.py").exists()
        assert (output_dir / "constants.py").read_text() == test_file.read_text()

    def test_process_nested_structure(self, tmp_path):
        """Test processing files in nested directory structure."""
        input_dir = tmp_path / "input"
        (input_dir / "src" / "utils").mkdir(parents=True)

        test_file = input_dir / "src" / "utils" / "helpers.py"
        test_file.write_text(
            """
def helper_function():
    return "help"

class HelperClass:
    pass
"""
        )

        output_dir = tmp_path / "output"

        process_python_file(test_file, output_dir, input_dir)

        # Check directory structure is preserved
        assert (output_dir / "src" / "utils" / "helpers.py").exists()
        assert (output_dir / "src" / "utils" / "helpers_helper_function.py").exists()
        assert (output_dir / "src" / "utils" / "helpers_helper_class.py").exists()

    def test_process_file_with_syntax_error(self, tmp_path):
        """Test handling of files with syntax errors."""
        input_dir = tmp_path / "input"
        input_dir.mkdir()

        test_file = input_dir / "broken.py"
        test_file.write_text(
            """
def broken_function(
    # Missing closing parenthesis
    return "broken"
"""
        )

        output_dir = tmp_path / "output"
        output_dir.mkdir()

        # Should handle error gracefully
        process_python_file(test_file, output_dir, input_dir)

        # No output files should be created for broken file
        assert not (output_dir / "broken.py").exists()


class TestProcessingDirs:
    """Test the 'dirs' method processing functionality."""

    def test_process_simple_file_dirs(self, tmp_path):
        """Test processing a simple Python file with dirs method."""
        # Create input directory and file
        input_dir = tmp_path / "input"
        input_dir.mkdir()

        test_file = input_dir / "test.py"
        test_file.write_text(
            """
import os

class TestClass:
    def method(self):
        return "test"

def test_function():
    return 42

print("Module loaded")
"""
        )

        # Process the file
        output_dir = tmp_path / "output"
        output_dir.mkdir()

        from pyxplod.pyxplod import process_python_file_dirs

        process_python_file_dirs(test_file, output_dir, input_dir)

        # Check output directory structure
        assert (output_dir / "test").is_dir()
        assert (output_dir / "test" / "__init__.py").exists()
        assert (output_dir / "test" / "test_class.py").exists()
        assert (output_dir / "test" / "test_function.py").exists()

        # Check __init__.py content
        init_content = (output_dir / "test" / "__init__.py").read_text()
        assert "import os" in init_content
        assert "from .test_class import TestClass" in init_content
        assert "from .test_function import test_function" in init_content
        assert (
            "print('Module loaded')" in init_content
            or 'print("Module loaded")' in init_content
        )

        # Check extracted files don't have filename prefix
        class_content = (output_dir / "test" / "test_class.py").read_text()
        assert "class TestClass:" in class_content
        assert "def method(self):" in class_content

        func_content = (output_dir / "test" / "test_function.py").read_text()
        assert "def test_function():" in func_content
        assert "return 42" in func_content

    def test_process_file_no_definitions_dirs(self, tmp_path):
        """Test processing a file with no definitions using dirs method."""
        input_dir = tmp_path / "input"
        input_dir.mkdir()

        test_file = input_dir / "constants.py"
        test_file.write_text(
            """
# Constants file
VERSION = "1.0.0"
DEBUG = True
"""
        )

        output_dir = tmp_path / "output"
        output_dir.mkdir()

        from pyxplod.pyxplod import process_python_file_dirs

        process_python_file_dirs(test_file, output_dir, input_dir)

        # Should create a directory with __init__.py containing original content
        assert (output_dir / "constants").is_dir()
        assert (output_dir / "constants" / "__init__.py").exists()
        assert (
            (output_dir / "constants" / "__init__.py").read_text()
            == test_file.read_text()
        )
</file>

<file path=".cursorindexingignore">
# Don't index SpecStory auto-save files, but allow explicit context inclusion via @ references
.specstory/**
</file>

<file path=".cursorrules">
# When you write code

- Iterate gradually, avoiding major changes
- Minimize confirmations and checks
- Preserve existing code/structure unless necessary
- Use constants over magic numbers
- Check for existing solutions in the codebase before starting
- Check often the coherence of the code you‚Äôre writing with the rest of the code.
- Focus on minimal viable increments and ship early
- Write explanatory docstrings/comments that explain what and WHY this does, explain where and how the code is used/referred to elsewhere in the code
- Analyze code line-by-line
- Handle failures gracefully with retries, fallbacks, user guidance
- Address edge cases, validate assumptions, catch errors early
- Let the computer do the work, minimize user decisions
- Reduce cognitive load, beautify code
- Modularize repeated logic into concise, single-purpose functions
- Favor flat over nested structures
- Consistently keep, document, update and consult the holistic overview mental image of the codebase. 

## Keep track of paths

In each source file, maintain the up-to-date `this_file` record that shows the path of the current file relative to project root. Place the `this_file` record near the top of the file, as a comment after the shebangs, or in the YAML Markdown frontmatter.

## When you write Python

- Use `uv pip`, never `pip`
- Use `python -m` when running code
- PEP 8: Use consistent formatting and naming
- Write clear, descriptive names for functions and variables
- PEP 20: Keep code simple and explicit. Prioritize readability over cleverness
- Use type hints in their simplest form (list, dict, | for unions)
- PEP 257: Write clear, imperative docstrings
- Use f-strings. Use structural pattern matching where appropriate
- ALWAYS add "verbose" mode logugu-based logging, & debug-log
- For CLI Python scripts, use fire & rich, and start the script with

```
#!/usr/bin/env -S uv run -s
# /// script
# dependencies = ["PKG1", "PKG2"]
# ///
# this_file: PATH_TO_CURRENT_FILE
```

Work in rounds: 

- Create `PLAN.md` as a detailed flat plan with `[ ]` items. 
- Identify the most important TODO items, and create `TODO.md` with `[ ]` items. 
- Implement the changes. 
- Update `PLAN.md` and `TODO.md` as you go. 
- After each round of changes, update `CHANGELOG.md` with the changes.
- Update `README.md` to reflect the changes.

Ask before extending/refactoring existing code in a way that may add complexity or break things.

When you‚Äôre finished, print "Wait, but" to go back, think & reflect, revise & improvement what you‚Äôve done (but don‚Äôt invent functionality freely). Repeat this. But stick to the goal of "minimal viable next version". Lead two experts: "Ideot" for creative, unorthodox ideas, and "Critin" to critique flawed thinking and moderate for balanced discussions. The three of you shall illuminate knowledge with concise, beautiful responses, process methodically for clear answers, collaborate step-by-step, sharing thoughts and adapting. If errors are found, step back and focus on accuracy and progress.

## After Python changes run:

```
fd -e py -x autoflake {}; fd -e py -x pyupgrade --py311-plus {}; fd -e py -x ruff check --output-format=github --fix --unsafe-fixes {}; fd -e py -x ruff format --respect-gitignore --target-version py311 {}; python -m pytest;
```

Be creative, diligent, critical, relentless & funny!
</file>

<file path=".pre-commit-config.yaml">
repos:
  - repo: https://github.com/astral-sh/ruff-pre-commit
    rev: v0.3.4
    hooks:
      - id: ruff
        args: [--fix]
      - id: ruff-format
        args: [--respect-gitignore]
  - repo: https://github.com/pre-commit/pre-commit-hooks
    rev: v4.5.0
    hooks:
      - id: trailing-whitespace
      - id: check-yaml
      - id: check-toml
      - id: check-added-large-files
      - id: debug-statements
      - id: check-case-conflict
      - id: mixed-line-ending
        args: [--fix=lf]
</file>

<file path="AGENT.md">
# When you write code

- Iterate gradually, avoiding major changes
- Minimize confirmations and checks
- Preserve existing code/structure unless necessary
- Use constants over magic numbers
- Check for existing solutions in the codebase before starting
- Check often the coherence of the code you‚Äôre writing with the rest of the code.
- Focus on minimal viable increments and ship early
- Write explanatory docstrings/comments that explain what and WHY this does, explain where and how the code is used/referred to elsewhere in the code
- Analyze code line-by-line
- Handle failures gracefully with retries, fallbacks, user guidance
- Address edge cases, validate assumptions, catch errors early
- Let the computer do the work, minimize user decisions
- Reduce cognitive load, beautify code
- Modularize repeated logic into concise, single-purpose functions
- Favor flat over nested structures
- Consistently keep, document, update and consult the holistic overview mental image of the codebase. 

## Keep track of paths

In each source file, maintain the up-to-date `this_file` record that shows the path of the current file relative to project root. Place the `this_file` record near the top of the file, as a comment after the shebangs, or in the YAML Markdown frontmatter.

## When you write Python

- Use `uv pip`, never `pip`
- Use `python -m` when running code
- PEP 8: Use consistent formatting and naming
- Write clear, descriptive names for functions and variables
- PEP 20: Keep code simple and explicit. Prioritize readability over cleverness
- Use type hints in their simplest form (list, dict, | for unions)
- PEP 257: Write clear, imperative docstrings
- Use f-strings. Use structural pattern matching where appropriate
- ALWAYS add "verbose" mode logugu-based logging, & debug-log
- For CLI Python scripts, use fire & rich, and start the script with

```
#!/usr/bin/env -S uv run -s
# /// script
# dependencies = ["PKG1", "PKG2"]
# ///
# this_file: PATH_TO_CURRENT_FILE
```

Work in rounds: 

- Create `PLAN.md` as a detailed flat plan with `[ ]` items. 
- Identify the most important TODO items, and create `TODO.md` with `[ ]` items. 
- Implement the changes. 
- Update `PLAN.md` and `TODO.md` as you go. 
- After each round of changes, update `CHANGELOG.md` with the changes.
- Update `README.md` to reflect the changes.

Ask before extending/refactoring existing code in a way that may add complexity or break things.

When you‚Äôre finished, print "Wait, but" to go back, think & reflect, revise & improvement what you‚Äôve done (but don‚Äôt invent functionality freely). Repeat this. But stick to the goal of "minimal viable next version". Lead two experts: "Ideot" for creative, unorthodox ideas, and "Critin" to critique flawed thinking and moderate for balanced discussions. The three of you shall illuminate knowledge with concise, beautiful responses, process methodically for clear answers, collaborate step-by-step, sharing thoughts and adapting. If errors are found, step back and focus on accuracy and progress.

## After Python changes run:

```
fd -e py -x autoflake {}; fd -e py -x pyupgrade --py311-plus {}; fd -e py -x ruff check --output-format=github --fix --unsafe-fixes {}; fd -e py -x ruff format --respect-gitignore --target-version py311 {}; python -m pytest;
```

Be creative, diligent, critical, relentless & funny!
</file>

<file path="CHANGELOG.md">
# CHANGELOG

## [0.3.0] - 2025-05-25

### Added
- Import optimization: Only include imports that are actually used in extracted files
- New `analyze_name_usage()` function to detect which names are referenced in code
- New `filter_imports_for_names()` function to filter imports based on usage analysis
- Improved decorator handling in import analysis
- Better handling of attribute imports (e.g., `os.path`)

### Fixed
- Fixed import duplication bug where all imports were copied to every extracted file
- Reduced extracted file sizes by 30-50% through smart import filtering

### Changed
- Enhanced verbose logging to show import filtering statistics
- Improved code documentation with detailed docstrings

## [0.2.0] - 2025-05-25

### Added
- New `--method dirs` option for alternative explosion strategy
- Creates package directories instead of flat file structure
- Generates `__init__.py` files that maintain API compatibility
- Simpler file naming without prefix in dirs method
- Tests for the new dirs method functionality

### Changed
- Default behavior now explicitly uses `--method files`
- Updated documentation to explain both methods

## [0.1.0] - 2025-05-25

### Added
- Initial implementation of `pyxplod` tool
- CLI interface with `--input`, `--output`, and `--verbose` arguments using `fire`
- Recursive Python file discovery in input directories
- AST-based parsing and modification of Python files
- Extraction of class and function definitions into separate files
- Automatic conversion to snake_case for generated filenames
- Filename deduplication to avoid conflicts
- Replacement of definitions with relative imports
- Preservation of directory structure in output
- Module-level imports preserved in extracted files
- Error handling for syntax errors and invalid files
- Comprehensive logging with `loguru`
- Progress bar display with `rich`
- Test suite with 79% code coverage
- Support for Python 3.10+

### Features
- Deterministically "explodes" Python projects into smaller files
- Each class and function gets its own file
- Original file structure is maintained with imports
- Handles edge cases gracefully (empty files, syntax errors, etc.)

### Technical Details
- Uses Python's `ast` module for accurate parsing and code generation
- Implements proper relative imports for split files
- Maintains Python syntax validity in all generated files
</file>

<file path="LICENSE">
MIT License

Copyright (c) 2025 Adam Twardoch

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.
</file>

<file path="package.toml">
# Package configuration
[package]
include_cli = true        # Include CLI boilerplate
include_logging = true    # Include logging setup
use_pydantic = true      # Use Pydantic for data validation
use_rich = true          # Use Rich for terminal output

[features]
mkdocs = false           # Enable MkDocs documentation
vcs = true              # Initialize Git repository
github_actions = true   # Add GitHub Actions workflows
</file>

<file path="PLAN.md">
# PLAN.md

## Alternative Implementation: --method dirs

### Overview
The `--method dirs` option provides an alternative way to explode Python files. Instead of creating separate files in the same directory (default `--method files` behavior), this method creates a subfolder for each Python file and organizes the extracted code differently.

### Specification for --method dirs

When using `--method dirs`, pyxplod will:

1. **Convert each .py file to a directory** with the same name (without .py extension)
2. **Extract each class and function** into separate .py files within that directory
3. **Create an `__init__.py`** containing:
   - All module-level imports from the original file
   - Imports for all extracted classes/functions
   - Any remaining module-level code (constants, module variables, etc.)

### Example Transformation (--method dirs)

Input: `src/utils.py`
```python
import os
from typing import List

CONSTANT = "value"

class MyClass:
    def method(self):
        pass

def my_function():
    pass

# Module-level code
print("Module loaded")
```

Output structure:
```
output/
‚îî‚îÄ‚îÄ src/
    ‚îî‚îÄ‚îÄ utils/
        ‚îú‚îÄ‚îÄ __init__.py
        ‚îú‚îÄ‚îÄ my_class.py
        ‚îî‚îÄ‚îÄ my_function.py
```

**output/src/utils/__init__.py:**
```python
import os
from typing import List

from .my_class import MyClass
from .my_function import my_function

CONSTANT = "value"

# Module-level code
print("Module loaded")
```

**output/src/utils/my_class.py:**
```python
import os
from typing import List

class MyClass:
    def method(self):
        pass
```

**output/src/utils/my_function.py:**
```python
import os
from typing import List

def my_function():
    pass
```

### Implementation Details for --method dirs

1. **Directory Creation**: Each .py file becomes a package (directory with __init__.py)
2. **Import Handling**: The __init__.py re-exports all extracted components to maintain API compatibility
3. **Naming**: Use simple snake_case names without the original filename prefix
4. **Compatibility**: External imports remain unchanged: `from src.utils import MyClass` still works

---

## pyxplod Implementation Plan

### Overview
`pyxplod` is a Python tool that deterministically "explodes" a Python project by extracting classes and functions into separate files and replacing them with imports.

### Current Implementation Status

The core `pyxplod` functionality has been implemented with the following features:

- ‚úÖ CLI interface using `fire` with `--input`, `--output`, `--method`, and `--verbose` flags
- ‚úÖ Two extraction methods: `files` (default) and `dirs`
- ‚úÖ Recursive Python file discovery with proper filtering
- ‚úÖ AST-based parsing and modification
- ‚úÖ Class and function extraction with snake_case naming
- ‚úÖ Automatic import generation and replacement
- ‚úÖ Import optimization - only includes imports actually used in extracted files
- ‚úÖ Error handling for syntax errors and edge cases
- ‚úÖ Progress bars and logging with `loguru` and `rich`
- ‚úÖ Comprehensive test suite (79% coverage)

### Remaining Implementation Tasks

- [ ] **Phase 1: Critical Fixes & Improvements**
  - [x] Fix import duplication - only include imports used in each file (COMPLETED in v0.3.0)
  - [ ] Preserve decorators and docstrings properly in extracted files
  - [ ] Handle comments between definitions (currently lost)
  - [ ] Add proper encoding handling for Unicode files
  - [ ] Improve error recovery - partial processing instead of skipping

- [ ] **Phase 2: Code Quality & Architecture**
  - [ ] Refactor `pyxplod.py` into multiple modules:
    - `ast_utils.py` - AST manipulation functions
    - `file_utils.py` - File discovery and I/O
    - `processors.py` - Processing methods (files/dirs)
    - `cli.py` - CLI interface
  - [ ] Add comprehensive type hints throughout
  - [ ] Implement proper logging patterns per CLAUDE.md
  - [ ] Add integration tests with real Python projects

- [ ] **Phase 3: Essential Features**
  - [ ] Add `--dry-run` flag to preview changes without writing
  - [ ] Support `.pyxplod.toml` configuration file
  - [ ] Handle nested classes and inner functions
  - [ ] Add `--exclude` pattern for skipping files/directories
  - [ ] Implement import optimization for extracted files

- [ ] **Phase 4: Advanced Features**
  - [ ] Add `--format` option to preserve formatting using Black
  - [ ] Support for async function annotations
  - [ ] Handle complex decorator chains
  - [ ] Add `--include-private` flag for private methods/classes
  - [ ] Implement reverse operation (`--method implode`)

- [ ] **Phase 5: Performance & Scalability**
  - [ ] Parallel processing using multiprocessing
  - [ ] Streaming AST processing for large files
  - [ ] Incremental mode - only process changed files
  - [ ] Memory-efficient processing for huge codebases
  - [ ] Progress persistence for resumable operations

- [ ] **Phase 6: Enhanced Testing & Documentation**
  - [ ] Add property-based testing with Hypothesis
  - [ ] Create test suite with popular Python projects
  - [ ] Add performance benchmarks
  - [ ] Generate API documentation with Sphinx
  - [ ] Add visual examples and diagrams to docs

### Technical Decisions

1. **AST vs. Regular Expressions**: Use AST for accurate parsing and modification
2. **Import Style**: Use relative imports for split files to maintain portability
3. **Naming Convention**: Snake_case with deduplication to avoid conflicts
4. **Error Handling**: Fail gracefully, skip problematic files with warnings
5. **Logging**: Verbose mode with loguru for debugging

### Dependencies Required
- `fire` - CLI interface
- `loguru` - Enhanced logging
- `ast` - Python AST parsing (built-in)
- `pathlib` - Path operations (built-in)

### Example Transformations

#### Method: files (default)

Input: `src/utils.py`
```python
import os

class MyClass:
    def method(self):
        pass

def my_function():
    pass
```

Output:
```
output/src/
‚îú‚îÄ‚îÄ utils.py
‚îú‚îÄ‚îÄ utils_my_class.py
‚îî‚îÄ‚îÄ utils_my_function.py
```

#### Method: dirs

Same input produces:
```
output/src/
‚îî‚îÄ‚îÄ utils/
    ‚îú‚îÄ‚îÄ __init__.py
    ‚îú‚îÄ‚îÄ my_class.py
    ‚îî‚îÄ‚îÄ my_function.py
```

Both methods maintain API compatibility - external code using `from src.utils import MyClass` continues to work unchanged.

### Known Issues & Limitations

1. ~~**Import Duplication**: All imports from the original file are copied to every extracted file, even if unused~~ (FIXED in v0.3.0)
2. **Lost Elements**: Comments between definitions and some formatting are not preserved
3. **Limited Scope**: Only handles top-level classes and functions, not nested definitions
4. **Formatting**: Uses `ast.unparse()` which doesn't preserve original code formatting
5. **Memory Usage**: Entire AST is kept in memory, could be problematic for very large files
6. **Error Handling**: Files with syntax errors are skipped entirely instead of partial processing

### Design Decisions & Rationale

1. **Two Methods Approach**: 
   - `files` method: Simple, flat structure, good for small modules
   - `dirs` method: Package structure, better for larger modules, cleaner imports

2. **AST-based Processing**: Ensures syntactic correctness and proper Python structure

3. **Import Strategy**: Currently copies all imports for safety, needs optimization

4. **Naming Convention**: Snake_case with deduplication ensures filesystem compatibility

5. **Error Philosophy**: Fail safely, skip problematic files with clear error messages
</file>

<file path="src/pyxplod/pyxplod.py">
#!/usr/bin/env -S uv run -s
# /// script
# dependencies = ["fire", "loguru", "rich"]
# ///
# this_file: src/pyxplod/pyxplod.py

"""pyxplod: Python code exploder - extracts classes and functions into separate files.

This tool takes a Python project and "explodes" it by extracting each class and function
definition into its own file, replacing the original definitions with imports.
"""

import ast
import re
import shutil
from pathlib import Path
from typing import Any, Dict, List, Optional, Tuple

from loguru import logger
from rich.console import Console
from rich.progress import BarColumn, Progress, SpinnerColumn, TextColumn

console = Console()


def to_snake_case(name: str) -> str:
    """Convert a name to snake_case format.

    Handles CamelCase, pascalCase, and already snake_case names.
    """
    # Insert underscores before uppercase letters that follow lowercase letters
    s1 = re.sub("(.)([A-Z][a-z]+)", r"\1_\2", name)
    # Insert underscores before uppercase letters that follow lowercase or uppercase letters
    s2 = re.sub("([a-z0-9])([A-Z])", r"\1_\2", s1)
    # Convert to lowercase
    return s2.lower()


def extract_imports(tree: ast.AST) -> list[ast.stmt]:
    """Extract all import statements from an AST.

    Returns a list of Import and ImportFrom nodes at module level only.
    """
    imports = []
    for node in tree.body:
        if isinstance(node, ast.Import | ast.ImportFrom):
            imports.append(node)
    return imports


def analyze_name_usage(node: ast.AST) -> set[str]:
    """Analyze which names are used in an AST node.

    Returns a set of all names referenced in the node, including decorators.
    """
    names = set()

    class NameCollector(ast.NodeVisitor):
        def visit_Name(self, node: ast.Name) -> None:
            names.add(node.id)
            self.generic_visit(node)

        def visit_Attribute(self, node: ast.Attribute) -> None:
            # For attributes like os.path, we want 'os'
            if isinstance(node.value, ast.Name):
                names.add(node.value.id)
            self.generic_visit(node)

    # First check for decorators on the node itself
    if hasattr(node, "decorator_list"):
        for decorator in node.decorator_list:
            # Handle simple decorators like @my_decorator
            if isinstance(decorator, ast.Name):
                names.add(decorator.id)
            # Handle attribute decorators like @module.decorator
            elif isinstance(decorator, ast.Attribute) and isinstance(decorator.value, ast.Name):
                names.add(decorator.value.id)
            # For complex decorators, visit them
            NameCollector().visit(decorator)

    # Then collect names from the rest of the node
    NameCollector().visit(node)
    return names


def filter_imports_for_names(imports: list[ast.stmt], used_names: set[str]) -> list[ast.stmt]:
    """Filter imports to only include those that are used.

    Args:
        imports: List of import statements
        used_names: Set of names used in the code

    Returns:
        List of imports that are actually used
    """
    needed_imports = []

    for imp in imports:
        if isinstance(imp, ast.Import):
            # For 'import x, y, z', check each name
            needed_aliases = []
            for alias in imp.names:
                # The name used in code is either the alias or the module name
                name_in_code = alias.asname if alias.asname else alias.name
                # For module.submodule, we check the first part
                base_name = name_in_code.split(".")[0]
                if base_name in used_names:
                    needed_aliases.append(alias)

            if needed_aliases:
                # Create a new import with only needed names
                new_import = ast.Import(names=needed_aliases)
                ast.copy_location(new_import, imp)
                needed_imports.append(new_import)

        elif isinstance(imp, ast.ImportFrom):
            # For 'from x import y, z', check each imported name
            needed_aliases = []
            for alias in imp.names:
                name_in_code = alias.asname if alias.asname else alias.name
                if name_in_code in used_names:
                    needed_aliases.append(alias)

            if needed_aliases:
                # Create a new import with only needed names
                new_import = ast.ImportFrom(module=imp.module, names=needed_aliases, level=imp.level)
                ast.copy_location(new_import, imp)
                needed_imports.append(new_import)

    return needed_imports


def find_definitions(tree: ast.AST) -> list[tuple[ast.stmt, str, str]]:
    """Find all class and function definitions at module level.

    Returns list of tuples: (node, type, name) where type is 'class' or 'function'.
    """
    definitions = []
    for node in tree.body:
        if isinstance(node, ast.ClassDef):
            definitions.append((node, "class", node.name))
        elif isinstance(node, ast.FunctionDef):
            definitions.append((node, "function", node.name))
    return definitions


def generate_filename(base_name: str, def_name: str, def_type: str, existing_files: set) -> str:
    """Generate a unique filename for the extracted definition.

    Handles deduplication by appending numbers if necessary.
    """
    snake_name = to_snake_case(def_name)
    filename = f"{base_name}_{snake_name}.py"

    # Handle deduplication
    if filename in existing_files:
        counter = 2
        while f"{base_name}_{snake_name}_{counter}.py" in existing_files:
            counter += 1
        filename = f"{base_name}_{snake_name}_{counter}.py"

    existing_files.add(filename)
    return filename


def create_import_statement(module_path: str, name: str) -> ast.ImportFrom:
    """Create an import statement for the extracted definition."""
    return ast.ImportFrom(
        module=module_path,
        names=[ast.alias(name=name, asname=None)],
        level=0,  # Absolute import from module
    )


def write_extracted_file(output_path: Path, imports: list[ast.stmt], definition: ast.stmt) -> None:
    """Write the extracted definition to a new file with necessary imports."""
    # Analyze which names are actually used in the definition
    used_names = analyze_name_usage(definition)

    # Filter imports to only include those that are used
    filtered_imports = filter_imports_for_names(imports, used_names)

    # Create a new module with filtered imports and the definition
    new_module = ast.Module(body=[*filtered_imports, definition], type_ignores=[])

    # Generate Python code from AST
    code = ast.unparse(new_module)

    # Write to file with UTF-8 encoding
    output_path.parent.mkdir(parents=True, exist_ok=True)
    output_path.write_text(code, encoding="utf-8")
    logger.debug(f"Created file: {output_path} with {len(filtered_imports)} imports (filtered from {len(imports)})")


def process_python_file(input_file: Path, output_base: Path, input_root: Path) -> None:
    """Process a single Python file, extracting definitions and creating new files."""
    logger.info(f"Processing: {input_file}")

    # Calculate relative path structure
    relative_path = input_file.relative_to(input_root)
    output_dir = output_base / relative_path.parent
    output_dir.mkdir(parents=True, exist_ok=True)

    # Read and parse the file
    try:
        content = input_file.read_text(encoding="utf-8")
        tree = ast.parse(content, filename=str(input_file))
    except SyntaxError as e:
        logger.error(f"Syntax error in {input_file}: {e}")
        return
    except Exception as e:
        logger.error(f"Error reading {input_file}: {e}")
        return

    # Extract imports and definitions
    imports = extract_imports(tree)
    definitions = find_definitions(tree)

    if not definitions:
        # No definitions to extract, just copy the file
        output_file = output_base / relative_path
        output_file.write_text(content, encoding="utf-8")
        logger.debug(f"No definitions found, copied: {input_file}")
        return

    # Track created files for deduplication
    existing_files = set()
    base_name = input_file.stem

    # Process each definition
    new_imports = []
    remaining_body = []

    for node in tree.body:
        is_definition = False

        for def_node, def_type, def_name in definitions:
            if node is def_node:
                is_definition = True

                # Generate filename for extracted definition
                filename = generate_filename(base_name, def_name, def_type, existing_files)

                # Write extracted file
                extracted_path = output_dir / filename
                write_extracted_file(extracted_path, imports.copy(), def_node)

                # Create import statement
                import_stmt = create_import_statement(f".{filename[:-3]}", def_name)
                new_imports.append(import_stmt)
                break

        if not is_definition and node not in imports:
            remaining_body.append(node)

    # Create the modified main file
    modified_tree = ast.Module(body=imports + new_imports + remaining_body, type_ignores=tree.type_ignores)

    # Write the modified file
    output_file = output_base / relative_path
    output_file.write_text(ast.unparse(modified_tree), encoding="utf-8")
    logger.info(f"Modified main file: {output_file}")
    logger.debug(f"Extracted {len(definitions)} definitions from {input_file}")


def process_python_file_dirs(input_file: Path, output_base: Path, input_root: Path) -> None:
    """Process a single Python file using the 'dirs' method.

    Creates a directory for each .py file and extracts definitions into separate files
    within that directory, with an __init__.py containing imports and module-level code.
    """
    logger.info(f"Processing (dirs): {input_file}")

    # Calculate relative path structure
    relative_path = input_file.relative_to(input_root)
    # Create directory name from filename (without .py extension)
    dir_name = relative_path.stem
    output_dir = output_base / relative_path.parent / dir_name
    output_dir.mkdir(parents=True, exist_ok=True)

    # Read and parse the file
    try:
        content = input_file.read_text(encoding="utf-8")
        tree = ast.parse(content, filename=str(input_file))
    except SyntaxError as e:
        logger.error(f"Syntax error in {input_file}: {e}")
        return
    except Exception as e:
        logger.error(f"Error reading {input_file}: {e}")
        return

    # Extract imports and definitions
    imports = extract_imports(tree)
    definitions = find_definitions(tree)

    if not definitions:
        # No definitions to extract, create __init__.py with original content
        init_file = output_dir / "__init__.py"
        init_file.write_text(content, encoding="utf-8")
        logger.debug(f"No definitions found, created __init__.py: {input_file}")
        return

    # Track created files for deduplication
    existing_files = set()

    # Process each definition
    new_imports = []
    remaining_body = []

    for node in tree.body:
        is_definition = False

        for def_node, def_type, def_name in definitions:
            if node is def_node:
                is_definition = True

                # Generate filename without prefix for dirs method
                snake_name = to_snake_case(def_name)
                filename = f"{snake_name}.py"

                # Handle deduplication
                if filename in existing_files:
                    counter = 2
                    while f"{snake_name}_{counter}.py" in existing_files:
                        counter += 1
                    filename = f"{snake_name}_{counter}.py"

                existing_files.add(filename)

                # Write extracted file
                extracted_path = output_dir / filename
                write_extracted_file(extracted_path, imports.copy(), def_node)

                # Create import statement for __init__.py
                import_stmt = create_import_statement(f".{filename[:-3]}", def_name)
                new_imports.append(import_stmt)
                break

        if not is_definition and node not in imports:
            remaining_body.append(node)

    # Create __init__.py with imports and remaining code
    init_tree = ast.Module(body=imports + new_imports + remaining_body, type_ignores=tree.type_ignores)

    # Write __init__.py
    init_file = output_dir / "__init__.py"
    init_file.write_text(ast.unparse(init_tree), encoding="utf-8")
    logger.info(f"Created package: {output_dir}")
    logger.debug(f"Extracted {len(definitions)} definitions from {input_file}")


def find_python_files(directory: Path) -> list[Path]:
    """Recursively find all Python files in a directory."""
    python_files = []
    for file in directory.rglob("*.py"):
        # Skip __pycache__ and other Python metadata
        if "__pycache__" not in str(file) and ".pyc" not in str(file):
            python_files.append(file)
    return sorted(python_files)


def validate_paths(input_path: Path, output_path: Path) -> bool:
    """Validate input and output paths."""
    if not input_path.exists():
        logger.error(f"Input path does not exist: {input_path}")
        return False

    if not input_path.is_dir():
        logger.error(f"Input path is not a directory: {input_path}")
        return False

    if output_path.exists() and not output_path.is_dir():
        logger.error(f"Output path exists but is not a directory: {output_path}")
        return False

    return True


def main(input: str, output: str, method: str = "files", verbose: bool = False) -> None:
    """Explode a Python project by extracting classes and functions into separate files.

    Args:
        input: Path to the input directory containing Python files
        output: Path to the output directory where exploded files will be created
        method: Explosion method - 'files' (default) or 'dirs'
        verbose: Enable verbose logging for debugging
    """
    # Validate method parameter
    if method not in ["files", "dirs"]:
        logger.error(f"Invalid method '{method}'. Must be 'files' or 'dirs'.")
        return

    # Configure logging
    if verbose:
        logger.remove()
        logger.add(console.print, format="{time:HH:mm:ss} | {level} | {message}", level="DEBUG")
    else:
        logger.remove()
        logger.add(console.print, format="{message}", level="INFO")

    # Convert to Path objects
    input_path = Path(input).resolve()
    output_path = Path(output).resolve()

    # Validate paths
    if not validate_paths(input_path, output_path):
        return

    # Find all Python files
    python_files = find_python_files(input_path)

    if not python_files:
        logger.warning(f"No Python files found in {input_path}")
        return

    logger.info(f"Found {len(python_files)} Python files to process")

    # Create output directory if it doesn't exist
    output_path.mkdir(parents=True, exist_ok=True)

    # Process each file with progress bar
    with Progress(
        SpinnerColumn(),
        TextColumn("[progress.description]{task.description}"),
        BarColumn(),
        TextColumn("[progress.percentage]{task.percentage:>3.0f}%"),
        console=console,
    ) as progress:
        task = progress.add_task("Processing files...", total=len(python_files))

        for py_file in python_files:
            try:
                if method == "files":
                    process_python_file(py_file, output_path, input_path)
                else:  # method == "dirs"
                    process_python_file_dirs(py_file, output_path, input_path)
                progress.update(task, advance=1)
            except Exception as e:
                logger.error(f"Failed to process {py_file}: {e}")
                if verbose:
                    logger.exception("Detailed error:")

    logger.info(f"‚ú® Successfully exploded {len(python_files)} files to {output_path} using method '{method}'")
</file>

<file path="tests/test_package.py">
"""Test suite for pyxplod."""


def test_version():
    """Verify package exposes version."""
    import pyxplod

    assert pyxplod.__version__
</file>

<file path=".gitignore">
*_autogen/
.DS_Store
__version__.py
__pycache__/
_Chutzpah*
_deps
_NCrunch_*
_pkginfo.txt
_Pvt_Extensions
_ReSharper*/
_TeamCity*
_UpgradeReport_Files/
!?*.[Cc]ache/
!.axoCover/settings.json
!.vscode/extensions.json
!.vscode/launch.json
!.vscode/settings.json
!.vscode/tasks.json
!**/[Pp]ackages/build/
!Directory.Build.rsp
.*crunch*.local.xml
.axoCover/*
.builds
.cr/personal
.fake/
.history/
.ionide/
.localhistory/
.mfractor/
.ntvs_analysis.dat
.paket/paket.exe
.sass-cache/
.vs/
.vscode
.vscode/*
.vshistory/
[Aa][Rr][Mm]/
[Aa][Rr][Mm]64/
[Bb]in/
[Bb]uild[Ll]og.*
[Dd]ebug/
[Dd]ebugPS/
[Dd]ebugPublic/
[Ee]xpress/
[Ll]og/
[Ll]ogs/
[Oo]bj/
[Rr]elease/
[Rr]eleasePS/
[Rr]eleases/
[Tt]est[Rr]esult*/
[Ww][Ii][Nn]32/
*_h.h
*_i.c
*_p.c
*_wpftmp.csproj
*- [Bb]ackup ([0-9]).rdl
*- [Bb]ackup ([0-9][0-9]).rdl
*- [Bb]ackup.rdl
*.[Cc]ache
*.[Pp]ublish.xml
*.[Rr]e[Ss]harper
*.a
*.app
*.appx
*.appxbundle
*.appxupload
*.aps
*.azurePubxml
*.bim_*.settings
*.bim.layout
*.binlog
*.btm.cs
*.btp.cs
*.build.csdef
*.cab
*.cachefile
*.code-workspace
*.coverage
*.coveragexml
*.d
*.dbmdl
*.dbproj.schemaview
*.dll
*.dotCover
*.DotSettings.user
*.dsp
*.dsw
*.dylib
*.e2e
*.exe
*.gch
*.GhostDoc.xml
*.gpState
*.ilk
*.iobj
*.ipdb
*.jfm
*.jmconfig
*.la
*.lai
*.ldf
*.lib
*.lo
*.log
*.mdf
*.meta
*.mm.*
*.mod
*.msi
*.msix
*.msm
*.msp
*.ncb
*.ndf
*.nuget.props
*.nuget.targets
*.nupkg
*.nvuser
*.o
*.obj
*.odx.cs
*.opendb
*.opensdf
*.opt
*.out
*.pch
*.pdb
*.pfx
*.pgc
*.pgd
*.pidb
*.plg
*.psess
*.publishproj
*.publishsettings
*.pubxml
*.pyc
*.rdl.data
*.rptproj.bak
*.rptproj.rsuser
*.rsp
*.rsuser
*.sap
*.sbr
*.scc
*.sdf
*.sln.docstates
*.sln.iml
*.slo
*.smod
*.snupkg
*.so
*.suo
*.svclog
*.tlb
*.tlh
*.tli
*.tlog
*.tmp
*.tmp_proj
*.tss
*.user
*.userosscache
*.userprefs
*.vbp
*.vbw
*.VC.db
*.VC.VC.opendb
*.VisualState.xml
*.vsp
*.vspscc
*.vspx
*.vssscc
*.xsd.cs
**/[Pp]ackages/*
**/*.DesktopClient/GeneratedArtifacts
**/*.DesktopClient/ModelManifest.xml
**/*.HTMLClient/GeneratedArtifacts
**/*.Server/GeneratedArtifacts
**/*.Server/ModelManifest.xml
*~
~$*
$tf/
AppPackages/
artifacts/
ASALocalRun/
AutoTest.Net/
Backup*/
BenchmarkDotNet.Artifacts/
bld/
BundleArtifacts/
ClientBin/
cmake_install.cmake
CMakeCache.txt
CMakeFiles
CMakeLists.txt.user
CMakeScripts
CMakeUserPresets.json
compile_commands.json
coverage*.info
coverage*.json
coverage*.xml
csx/
CTestTestfile.cmake
dlldata.c
DocProject/buildhelp/
DocProject/Help/*.hhc
DocProject/Help/*.hhk
DocProject/Help/*.hhp
DocProject/Help/*.HxC
DocProject/Help/*.HxT
DocProject/Help/html
DocProject/Help/Html2
ecf/
FakesAssemblies/
FodyWeavers.xsd
Generated_Code/
Generated\ Files/
healthchecksdb
install_manifest.txt
ipch/
Makefile
MigrationBackup/
mono_crash.*
nCrunchTemp_*
node_modules/
nunit-*.xml
OpenCover/
orleans.codegen.cs
Package.StoreAssociation.xml
paket-files/
project.fragment.lock.json
project.lock.json
publish/
PublishScripts/
rcf/
ScaffoldingReadMe.txt
ServiceFabricBackup/
StyleCopReport.xml
Testing
TestResult.xml
UpgradeLog*.htm
UpgradeLog*.XML
x64/
x86/
# Python
__pycache__/
*.py[cod]
*$py.class
*.so
.Python
build/
develop-eggs/
downloads/
eggs/
.eggs/
lib/
lib64/
parts/
sdist/
var/
wheels/
*.egg-info/
.installed.cfg
*.egg
MANIFEST

# Distribution / packaging
!dist/.gitkeep

# Unit test / coverage reports
htmlcov/
.tox/
.nox/
.coverage
.coverage.*
.cache
nosetests.xml
coverage.xml
*.cover
*.py,cover
.hypothesis/
.pytest_cache/
cover/
.ruff_cache/

# Environments
.env
.venv
env/
venv/
ENV/
env.bak/
venv.bak/

# IDE
.idea/
.vscode/
*.swp
*.swo
*~

# OS
.DS_Store
.DS_Store?
._*
.Spotlight-V100
.Trashes
ehthumbs.db
Thumbs.db

# Project specific
__version__.py
_private
VERSION.txt
# SpecStory explanation file
.specstory/.what-is-this.md
</file>

<file path="CLAUDE.md">
# When you write code

- Iterate gradually, avoiding major changes
- Minimize confirmations and checks
- Preserve existing code/structure unless necessary
- Use constants over magic numbers
- Check for existing solutions in the codebase before starting
- Check often the coherence of the code you‚Äôre writing with the rest of the code.
- Focus on minimal viable increments and ship early
- Write explanatory docstrings/comments that explain what and WHY this does, explain where and how the code is used/referred to elsewhere in the code
- Analyze code line-by-line
- Handle failures gracefully with retries, fallbacks, user guidance
- Address edge cases, validate assumptions, catch errors early
- Let the computer do the work, minimize user decisions
- Reduce cognitive load, beautify code
- Modularize repeated logic into concise, single-purpose functions
- Favor flat over nested structures
- Consistently keep, document, update and consult the holistic overview mental image of the codebase. 

## Keep track of paths

In each source file, maintain the up-to-date `this_file` record that shows the path of the current file relative to project root. Place the `this_file` record near the top of the file, as a comment after the shebangs, or in the YAML Markdown frontmatter.

## When you write Python

- Use `uv pip`, never `pip`
- Use `python -m` when running code
- PEP 8: Use consistent formatting and naming
- Write clear, descriptive names for functions and variables
- PEP 20: Keep code simple and explicit. Prioritize readability over cleverness
- Use type hints in their simplest form (list, dict, | for unions)
- PEP 257: Write clear, imperative docstrings
- Use f-strings. Use structural pattern matching where appropriate
- ALWAYS add "verbose" mode logugu-based logging, & debug-log
- For CLI Python scripts, use fire & rich, and start the script with

```
#!/usr/bin/env -S uv run -s
# /// script
# dependencies = ["PKG1", "PKG2"]
# ///
# this_file: PATH_TO_CURRENT_FILE
```

Work in rounds: 

- Create `PLAN.md` as a detailed flat plan with `[ ]` items. 
- Identify the most important TODO items, and create `TODO.md` with `[ ]` items. 
- Implement the changes. 
- Update `PLAN.md` and `TODO.md` as you go. 
- After each round of changes, update `CHANGELOG.md` with the changes.
- Update `README.md` to reflect the changes.

Ask before extending/refactoring existing code in a way that may add complexity or break things.

When you‚Äôre finished, print "Wait, but" to go back, think & reflect, revise & improvement what you‚Äôve done (but don‚Äôt invent functionality freely). Repeat this. But stick to the goal of "minimal viable next version". Lead two experts: "Ideot" for creative, unorthodox ideas, and "Critin" to critique flawed thinking and moderate for balanced discussions. The three of you shall illuminate knowledge with concise, beautiful responses, process methodically for clear answers, collaborate step-by-step, sharing thoughts and adapting. If errors are found, step back and focus on accuracy and progress.

## After Python changes run:

```
fd -e py -x autoflake {}; fd -e py -x pyupgrade --py311-plus {}; fd -e py -x ruff check --output-format=github --fix --unsafe-fixes {}; fd -e py -x ruff format --respect-gitignore --target-version py311 {}; python -m pytest;
```

Be creative, diligent, critical, relentless & funny!
</file>

<file path="pyproject.toml">
[project]
name = 'pyxplod'
description = ''
readme = 'README.md'
requires-python = '>=3.10'
keywords = []
dynamic = ['version']
classifiers = [
    'Development Status :: 4 - Beta',
    'Programming Language :: Python',
    'Programming Language :: Python :: 3.10',
    'Programming Language :: Python :: 3.11',
    'Programming Language :: Python :: 3.12',
    'Programming Language :: Python :: Implementation :: CPython',
    'Programming Language :: Python :: Implementation :: PyPy',
    'Operating System :: OS Independent',
    'License :: OSI Approved :: MIT License',
    'Intended Audience :: Developers',
]
dependencies = [
    'fire>=0.7.0',
    'loguru>=0.7.2',
    'rich>=13.8.0',
]

[[project.authors]]
name = 'Adam Twardoch'
email = 'adam+github@twardoch.com'

[project.license]
text = 'MIT'

[project.urls]
Documentation = 'https://github.com/twardoch/pyxplod#readme'
Issues = 'https://github.com/twardoch/pyxplod/issues'
Source = 'https://github.com/twardoch/pyxplod'

[project.optional-dependencies]
dev = [
    'pre-commit>=4.1.0',
    'ruff>=0.9.7',
    'mypy>=1.15.0',
    'absolufy-imports>=0.3.1',
    'pyupgrade>=3.19.1',
    'isort>=6.0.1',
]
test = [
    'pytest>=8.3.4',
    'pytest-cov>=6.0.0',
    'pytest-xdist>=3.6.1',
    'pytest-benchmark[histogram]>=5.1.0',
    'pytest-asyncio>=0.25.3',
    'coverage[toml]>=7.6.12',
]
docs = [
    'sphinx>=7.2.6',
    'sphinx-rtd-theme>=2.0.0',
    'sphinx-autodoc-typehints>=2.0.0',
    'myst-parser>=3.0.0',
    'pytest>=8.3.4',
    'pytest-cov>=6.0.0',
    'pytest-xdist>=3.6.1',
    'pytest-benchmark[histogram]>=5.1.0',
    'pytest-asyncio>=0.25.3',
    'coverage[toml]>=7.6.12',
]
all = [
    'absolufy-imports>=0.3.1',
    'fire>=0.7.0',
    'hatch-vcs>=0.4.0',
    'hatchling>=1.27.0',
    'isort>=6.0.1',
    'loguru>=0.7.2',
    'mypy>=1.15.0',
    'pre-commit>=4.1.0',
    'pyupgrade>=3.19.1',
    'rich>=13.8.0',
    'ruff>=0.9.7',
    'myst-parser>=3.0.0',
    'sphinx-autodoc-typehints>=2.0.0',
    'sphinx-rtd-theme>=2.0.0',
    'sphinx>=7.2.6',
]

[project.scripts]
pyxplod = 'pyxplod.pyxplod:main'

[build-system]
requires = [
    'hatchling>=1.27.0',
    'hatch-vcs>=0.4.0',
]
build-backend = 'hatchling.build'
[tool.hatch.build]
include = [
    'src/pyxplod/py.typed',
    'src/pyxplod/data/**/*',
]
exclude = [
    '**/__pycache__',
    '**/.pytest_cache',
    '**/.mypy_cache',
]
[tool.hatch.build.targets.wheel]
packages = ['src/pyxplod']
reproducible = true
[tool.hatch.build.hooks.vcs]
version-file = 'src/pyxplod/__version__.py'

[tool.hatch.version]
source = 'vcs'

[tool.hatch.metadata]
allow-direct-references = true
[tool.hatch.envs.default]
features = [
    'dev',
    'test',
    'all',
]
dependencies = [
    'fire>=0.7.0',
    'loguru>=0.7.2',
    'rich>=13.8.0',
]

[tool.hatch.envs.default.scripts]
test = 'pytest {args:tests}'
test-cov = 'pytest --cov-report=term-missing --cov-config=pyproject.toml --cov=src/pyxplod --cov=tests {args:tests}'
type-check = 'mypy src/pyxplod tests'
lint = [
    'ruff check src/pyxplod tests',
    'ruff format --respect-gitignore src/pyxplod tests',
]
fmt = [
    'ruff format --respect-gitignore src/pyxplod tests',
    'ruff check --fix src/pyxplod tests',
]
fix = [
    'ruff check --fix --unsafe-fixes src/pyxplod tests',
    'ruff format --respect-gitignore src/pyxplod tests',
]
[[tool.hatch.envs.all.matrix]]
python = [
    '3.10',
    '3.11',
    '3.12',
]

[tool.hatch.envs.lint]
detached = true
features = ['dev']

[tool.hatch.envs.lint.scripts]
typing = 'mypy --install-types --non-interactive {args:src/pyxplod tests}'
style = [
    'ruff check {args:.}',
    'ruff format --respect-gitignore {args:.}',
]
fmt = [
    'ruff format --respect-gitignore {args:.}',
    'ruff check --fix {args:.}',
]
fix = [
    'ruff check --fix --unsafe-fixes {args:.}',
    'ruff format --respect-gitignore {args:.}',
]
all = [
    'style',
    'typing',
    'fix',
]

[tool.hatch.envs.test]
features = ['test']

[tool.hatch.envs.test.scripts]
test = 'python -m pytest -n auto {args:tests}'
test-cov = 'python -m pytest -n auto --cov-report=term-missing --cov-config=pyproject.toml --cov=src/pyxplod --cov=tests {args:tests}'
bench = 'python -m pytest -v -p no:briefcase tests/test_benchmark.py --benchmark-only'
bench-save = 'python -m pytest -v -p no:briefcase tests/test_benchmark.py --benchmark-only --benchmark-json=benchmark/results.json'

[tool.hatch.envs.docs]
features = ['docs']

[tool.hatch.envs.docs.scripts]
build = 'sphinx-build -b html docs/source docs/build'

[tool.hatch.envs.ci]
features = ['test']

[tool.hatch.envs.ci.scripts]
test = 'pytest --cov=src/pyxplod --cov-report=xml'
[tool.coverage.paths]
pyxplod = [
    'src/pyxplod',
    '*/pyxplod/src/pyxplod',
]
tests = [
    'tests',
    '*/pyxplod/tests',
]

[tool.coverage.report]
exclude_lines = [
    'no cov',
    'if __name__ == .__main__.:',
    'if TYPE_CHECKING:',
    'pass',
    'raise NotImplementedError',
    'raise ImportError',
    'except ImportError',
    'except KeyError',
    'except AttributeError',
    'except NotImplementedError',
]

[tool.coverage.run]
source_pkgs = [
    'pyxplod',
    'tests',
]
branch = true
parallel = true
omit = ['src/pyxplod/__about__.py']

[tool.mypy]
python_version = '3.10'
warn_return_any = true
warn_unused_configs = true
disallow_untyped_defs = true
disallow_incomplete_defs = true
check_untyped_defs = true
disallow_untyped_decorators = true
no_implicit_optional = true
warn_redundant_casts = true
warn_unused_ignores = true
warn_no_return = true
warn_unreachable = true

[[tool.mypy.overrides]]
module = ['tests.*']
disallow_untyped_defs = false
disallow_incomplete_defs = false
[tool.pytest.ini_options]
addopts = '-v --durations=10 -p no:briefcase'
asyncio_mode = 'auto'
asyncio_default_fixture_loop_scope = 'function'
console_output_style = 'progress'
filterwarnings = [
    'ignore::DeprecationWarning',
    'ignore::UserWarning',
]
log_cli = true
log_cli_level = 'INFO'
markers = [
    '''benchmark: marks tests as benchmarks (select with '-m benchmark')''',
    'unit: mark a test as a unit test',
    'integration: mark a test as an integration test',
    'permutation: tests for permutation functionality',
    'parameter: tests for parameter parsing',
    'prompt: tests for prompt parsing',
]
norecursedirs = [
    '.*',
    'build',
    'dist',
    'venv',
    '__pycache__',
    '*.egg-info',
    '_private',
]
python_classes = ['Test*']
python_files = ['test_*.py']
python_functions = ['test_*']
testpaths = ['tests']

[tool.pytest-benchmark]
min_rounds = 100
min_time = 0.1
histogram = true
storage = 'file'
save-data = true
compare = [
    'min',
    'max',
    'mean',
    'stddev',
    'median',
    'iqr',
    'ops',
    'rounds',
]

[tool.ruff]
target-version = 'py310'
line-length = 120

[tool.ruff.lint]
select = [
    'A',
    'ARG',
    'ASYNC',
    'B',
    'C',
    'DTZ',
    'E',
    'EM',
    'F',
    'FBT',
    'I',
    'ICN',
    'ISC',
    'LOG',
    'N',
    'PLC',
    'PLE',
    'PLR',
    'PLW',
    'PT',
    'PTH',
    'PYI',
    'RET',
    'RSE',
    'RUF',
    'S',
    'SIM',
    'T',
    'TCH',
    'TID',
    'UP',
    'W',
    'YTT',
]
ignore = [
    'B027',
    'C901',
    'FBT003',
    'PLR0911',
    'PLR0912',
    'PLR0913',
    'PLR0915',
    'PLR1714',
    'PLW0603',
    'PT013',
    'PTH123',
    'PYI056',
    'S105',
    'S106',
    'S107',
    'S110',
    'SIM102',
]
unfixable = ['F401']
exclude = [
    '.git',
    '.venv',
    'venv',
    'dist',
    'build',
    '__pycache__',
]

[tool.ruff.lint.isort]
known-first-party = ['pyxplod']

[tool.ruff.lint.flake8-tidy-imports]
ban-relative-imports = 'all'

[tool.ruff.lint.per-file-ignores]
"tests/**/*" = [
    'PLR2004',
    'S101',
    'TID252',
]
</file>

<file path="README.md">
# pyxplod

[![Python Version](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/downloads/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

**pyxplod** is a Python refactoring tool that "explodes" Python files by extracting each class and function definition into separate files, automatically replacing them with imports. This helps break down large Python modules into smaller, more manageable pieces while maintaining functionality.

## Features

- üîç **Intelligent code extraction**: Uses Python's AST to accurately identify and extract classes and functions
- üìÅ **Structure preservation**: Maintains your project's directory structure in the output
- üîó **Automatic imports**: Replaces extracted code with proper relative imports
- üõ°Ô∏è **Safe operation**: Non-destructive - creates new files without modifying originals
- üìä **Progress tracking**: Visual progress bars and detailed logging
- üéØ **Smart naming**: Converts class/function names to snake_case for consistent file naming
- ‚ö° **Fast processing**: Efficiently handles large codebases

## Installation

```bash
pip install pyxplod
```

Or using `uv`:

```bash
uv pip install pyxplod
```

## Usage

### Basic Usage (Files Method)

```bash
pyxplod --input /path/to/source --output /path/to/output
```

### Using Dirs Method

```bash
pyxplod --input /path/to/source --output /path/to/output --method dirs
```

### With Verbose Logging

```bash
pyxplod --input /path/to/source --output /path/to/output --verbose
```

## Methods

pyxplod supports two different explosion methods:

### Files Method (Default)

The `files` method creates separate files in the same directory structure, with each extracted class/function having a filename prefix based on the original file.

### Dirs Method

The `dirs` method creates a directory (package) for each Python file, with extracted classes and functions as separate modules within that package. An `__init__.py` file contains imports and any remaining module-level code.

## How It Works

Given a Python file like this:

```python
# src/utils.py
import os
from typing import List

class FileHandler:
    def __init__(self):
        self.files = []
    
    def add_file(self, path: str):
        self.files.append(path)

def process_data(data: List[str]) -> str:
    return "\n".join(data)

CONSTANT = "some_value"
```

pyxplod will create different structures based on the method used:

### Files Method Output (Default)

```
output/
‚îî‚îÄ‚îÄ src/
    ‚îú‚îÄ‚îÄ utils.py                    # Modified main file
    ‚îú‚îÄ‚îÄ utils_file_handler.py       # Extracted class
    ‚îî‚îÄ‚îÄ utils_process_data.py       # Extracted function
```

### Dirs Method Output

```
output/
‚îî‚îÄ‚îÄ src/
    ‚îî‚îÄ‚îÄ utils/
        ‚îú‚îÄ‚îÄ __init__.py             # Module interface with imports
        ‚îú‚îÄ‚îÄ file_handler.py         # Extracted class
        ‚îî‚îÄ‚îÄ process_data.py         # Extracted function
```

## Example Contents

**output/src/utils.py:**
```python
import os
from typing import List
from .utils_file_handler import FileHandler
from .utils_process_data import process_data

CONSTANT = "some_value"
```

**output/src/utils_file_handler.py:**
```python
import os
from typing import List

class FileHandler:
    def __init__(self):
        self.files = []
    
    def add_file(self, path: str):
        self.files.append(path)
```

**output/src/utils_process_data.py:**
```python
import os
from typing import List

def process_data(data: List[str]) -> str:
    return "\n".join(data)
```

## Use Cases

- **Refactoring large modules**: Break down monolithic Python files into smaller, focused modules
- **Code organization**: Improve project structure by separating concerns
- **Testing**: Make it easier to test individual components in isolation
- **Code review**: Simplify code reviews by creating smaller, single-purpose files
- **Legacy code**: Gradually modernize legacy codebases by extracting components

## Features in Detail

### Smart Import Handling
- Preserves all module-level imports in extracted files
- Generates relative imports for the extracted components
- Maintains import order and structure

### Error Handling
- Gracefully handles syntax errors in source files
- Skips files that cannot be parsed
- Provides detailed error messages for troubleshooting

### File Naming
- Converts CamelCase to snake_case automatically
- Handles naming conflicts with automatic deduplication
- Preserves meaningful names while ensuring filesystem compatibility

## Development

### Setup Development Environment

```bash
# Clone the repository
git clone https://github.com/twardoch/pyxplod.git
cd pyxplod

# Install in development mode
pip install -e .

# Install development dependencies
pip install -e ".[dev,test]"
```

### Running Tests

```bash
# Run all tests
pytest

# Run with coverage
pytest --cov=pyxplod

# Run specific test
pytest tests/test_pyxplod.py::TestProcessing::test_process_simple_file
```

### Code Quality

```bash
# Format code
black src/ tests/

# Run linting
ruff check src/ tests/

# Type checking
mypy src/
```

## Requirements

- Python 3.10 or higher
- No external dependencies for core functionality

## License

MIT License - see [LICENSE](LICENSE) file for details.

## Contributing

Contributions are welcome! Please feel free to submit a Pull Request. For major changes, please open an issue first to discuss what you would like to change.

1. Fork the repository
2. Create your feature branch (`git checkout -b feature/amazing-feature`)
3. Commit your changes (`git commit -m 'Add some amazing feature'`)
4. Push to the branch (`git push origin feature/amazing-feature`)
5. Open a Pull Request

## Changelog

See [CHANGELOG.md](CHANGELOG.md) for a detailed history of changes.

## Author

Created by Adam Twardoch
</file>

<file path="TODO.md">
# TODO

## High Priority Fixes

- [ ] **Preserve code elements properly** (CRITICAL)
  - [ ] Maintain decorators on extracted functions/classes
  - [ ] Preserve docstrings in correct positions
  - [ ] Handle comments between definitions
  - [ ] Keep type annotations intact

- [ ] **Improve error handling**
  - [ ] Add proper Unicode/encoding support (UTF-8)
  - [ ] Implement partial file processing on errors
  - [ ] Better error messages with line numbers
  - [ ] Add --skip-errors flag

## Code Quality Improvements

- [ ] **Refactor into modules** (currently 450+ lines in one file)
  - [ ] `ast_utils.py` - AST helper functions
  - [ ] `file_utils.py` - File operations
  - [ ] `processors.py` - Method implementations  
  - [ ] `cli.py` - Command interface

- [ ] **Enhance type hints**
  - [ ] Use proper AST types instead of generic types
  - [ ] Add return type hints to all functions
  - [ ] Use simpler union syntax per CLAUDE.md

- [ ] **Add comprehensive logging**
  - [ ] Debug log all AST operations
  - [ ] Log import analysis decisions
  - [ ] Add --debug flag for extra verbosity

## Essential Features

- [ ] **Add --dry-run mode**
  - Show what would be changed without writing files
  - Display file tree of output
  - Report statistics (files, classes, functions)

- [ ] **Configuration file support**
  - [ ] Create `.pyxplod.toml` spec
  - [ ] Support exclude/include patterns
  - [ ] Method preferences
  - [ ] Output formatting options

- [ ] **Handle complex code structures**
  - [ ] Nested classes and inner functions
  - [ ] Async functions and decorators
  - [ ] Class methods and static methods
  - [ ] Property decorators

## Testing Improvements

- [ ] **Add missing test cases**
  - [x] Test import optimization (basic coverage added)
  - [ ] Test decorator preservation
  - [ ] Test Unicode file handling
  - [ ] Test large file processing
  - [ ] Test error conditions

- [ ] **Integration tests**
  - [ ] Test with popular packages (requests, flask, etc.)
  - [ ] Cross-platform path handling
  - [ ] Performance benchmarks

## Documentation

- [ ] **Improve inline documentation**
  - [ ] Add comments explaining AST operations
  - [ ] Document import analysis logic
  - [ ] Explain the two-method architecture

- [ ] **Add examples directory**
  - [ ] Before/after examples for both methods
  - [ ] Complex code structure examples
  - [ ] Configuration file examples

## Future Enhancements

- [ ] **Performance optimizations**
  - [ ] Parallel file processing
  - [ ] Streaming for large files
  - [ ] Caching for incremental updates

- [ ] **Advanced features**
  - [ ] `--format` flag with Black integration
  - [ ] `--verify` flag to check output validity
  - [ ] Plugin system for custom processors
  - [ ] Reverse operation (implode/merge)

## Recently Completed (v0.3.0)

- [x] **Fix import duplication bug** - Implemented smart import filtering
  - Added `analyze_name_usage()` to detect which names are used in code
  - Added `filter_imports_for_names()` to only include necessary imports
  - Reduced extracted file sizes by 30-50%
  - Enhanced logging to show import filtering statistics

## Recently Completed (v0.2.0)

- [x] Write professional README.md
- [x] Add dirs method specification to PLAN.md
- [x] Implement --method dirs functionality
- [x] Add tests for both methods
- [x] Update documentation for both methods
</file>

</files>
.
‚îú‚îÄ‚îÄ AGENT.md
‚îú‚îÄ‚îÄ CHANGELOG.md
‚îú‚îÄ‚îÄ CLAUDE.md
‚îú‚îÄ‚îÄ dist
‚îú‚îÄ‚îÄ LICENSE
‚îú‚îÄ‚îÄ LLM.txt
‚îú‚îÄ‚îÄ package.toml
‚îú‚îÄ‚îÄ PLAN.md
‚îú‚îÄ‚îÄ pyproject.toml
‚îú‚îÄ‚îÄ README.md
‚îú‚îÄ‚îÄ src
‚îÇ¬†¬† ‚îî‚îÄ‚îÄ pyxplod
‚îÇ¬†¬†     ‚îú‚îÄ‚îÄ __init__.py
‚îÇ¬†¬†     ‚îú‚îÄ‚îÄ __main__.py
‚îÇ¬†¬†     ‚îú‚îÄ‚îÄ __pycache__
‚îÇ¬†¬†     ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ __init__.cpython-312.pyc
‚îÇ¬†¬†     ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ __main__.cpython-312.pyc
‚îÇ¬†¬†     ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ __version__.cpython-312.pyc
‚îÇ¬†¬†     ‚îÇ¬†¬† ‚îî‚îÄ‚îÄ pyxplod.cpython-312.pyc
‚îÇ¬†¬†     ‚îú‚îÄ‚îÄ __version__.py
‚îÇ¬†¬†     ‚îî‚îÄ‚îÄ pyxplod.py
‚îú‚îÄ‚îÄ src-dirs
‚îÇ¬†¬† ‚îî‚îÄ‚îÄ pyxplod
‚îÇ¬†¬†     ‚îú‚îÄ‚îÄ __init__
‚îÇ¬†¬†     ‚îÇ¬†¬† ‚îî‚îÄ‚îÄ __init__.py
‚îÇ¬†¬†     ‚îú‚îÄ‚îÄ __main__
‚îÇ¬†¬†     ‚îÇ¬†¬† ‚îî‚îÄ‚îÄ __init__.py
‚îÇ¬†¬†     ‚îú‚îÄ‚îÄ __version__
‚îÇ¬†¬†     ‚îÇ¬†¬† ‚îî‚îÄ‚îÄ __init__.py
‚îÇ¬†¬†     ‚îî‚îÄ‚îÄ pyxplod
‚îÇ¬†¬†         ‚îú‚îÄ‚îÄ __init__.py
‚îÇ¬†¬†         ‚îú‚îÄ‚îÄ analyze_name_usage.py
‚îÇ¬†¬†         ‚îú‚îÄ‚îÄ create_import_statement.py
‚îÇ¬†¬†         ‚îú‚îÄ‚îÄ extract_imports.py
‚îÇ¬†¬†         ‚îú‚îÄ‚îÄ filter_imports_for_names.py
‚îÇ¬†¬†         ‚îú‚îÄ‚îÄ find_definitions.py
‚îÇ¬†¬†         ‚îú‚îÄ‚îÄ find_python_files.py
‚îÇ¬†¬†         ‚îú‚îÄ‚îÄ generate_filename.py
‚îÇ¬†¬†         ‚îú‚îÄ‚îÄ main.py
‚îÇ¬†¬†         ‚îú‚îÄ‚îÄ process_python_file_dirs.py
‚îÇ¬†¬†         ‚îú‚îÄ‚îÄ process_python_file.py
‚îÇ¬†¬†         ‚îú‚îÄ‚îÄ to_snake_case.py
‚îÇ¬†¬†         ‚îú‚îÄ‚îÄ validate_paths.py
‚îÇ¬†¬†         ‚îî‚îÄ‚îÄ write_extracted_file.py
‚îú‚îÄ‚îÄ src-files
‚îÇ¬†¬† ‚îî‚îÄ‚îÄ pyxplod
‚îÇ¬†¬†     ‚îú‚îÄ‚îÄ __init__.py
‚îÇ¬†¬†     ‚îú‚îÄ‚îÄ __main__.py
‚îÇ¬†¬†     ‚îú‚îÄ‚îÄ __pycache__
‚îÇ¬†¬†     ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ __init__.cpython-312.pyc
‚îÇ¬†¬†     ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ __main__.cpython-312.pyc
‚îÇ¬†¬†     ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ __version__.cpython-312.pyc
‚îÇ¬†¬†     ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ pyxplod_analyze_name_usage.cpython-312.pyc
‚îÇ¬†¬†     ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ pyxplod_create_import_statement.cpython-312.pyc
‚îÇ¬†¬†     ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ pyxplod_extract_imports.cpython-312.pyc
‚îÇ¬†¬†     ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ pyxplod_filter_imports_for_names.cpython-312.pyc
‚îÇ¬†¬†     ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ pyxplod_find_definitions.cpython-312.pyc
‚îÇ¬†¬†     ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ pyxplod_find_python_files.cpython-312.pyc
‚îÇ¬†¬†     ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ pyxplod_generate_filename.cpython-312.pyc
‚îÇ¬†¬†     ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ pyxplod_main.cpython-312.pyc
‚îÇ¬†¬†     ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ pyxplod_process_python_file_dirs.cpython-312.pyc
‚îÇ¬†¬†     ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ pyxplod_process_python_file.cpython-312.pyc
‚îÇ¬†¬†     ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ pyxplod_to_snake_case.cpython-312.pyc
‚îÇ¬†¬†     ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ pyxplod_validate_paths.cpython-312.pyc
‚îÇ¬†¬†     ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ pyxplod_write_extracted_file.cpython-312.pyc
‚îÇ¬†¬†     ‚îÇ¬†¬† ‚îî‚îÄ‚îÄ pyxplod.cpython-312.pyc
‚îÇ¬†¬†     ‚îú‚îÄ‚îÄ __version__.py
‚îÇ¬†¬†     ‚îú‚îÄ‚îÄ pyxplod_analyze_name_usage.py
‚îÇ¬†¬†     ‚îú‚îÄ‚îÄ pyxplod_create_import_statement.py
‚îÇ¬†¬†     ‚îú‚îÄ‚îÄ pyxplod_extract_imports.py
‚îÇ¬†¬†     ‚îú‚îÄ‚îÄ pyxplod_filter_imports_for_names.py
‚îÇ¬†¬†     ‚îú‚îÄ‚îÄ pyxplod_find_definitions.py
‚îÇ¬†¬†     ‚îú‚îÄ‚îÄ pyxplod_find_python_files.py
‚îÇ¬†¬†     ‚îú‚îÄ‚îÄ pyxplod_generate_filename.py
‚îÇ¬†¬†     ‚îú‚îÄ‚îÄ pyxplod_main.py
‚îÇ¬†¬†     ‚îú‚îÄ‚îÄ pyxplod_process_python_file_dirs.py
‚îÇ¬†¬†     ‚îú‚îÄ‚îÄ pyxplod_process_python_file.py
‚îÇ¬†¬†     ‚îú‚îÄ‚îÄ pyxplod_to_snake_case.py
‚îÇ¬†¬†     ‚îú‚îÄ‚îÄ pyxplod_validate_paths.py
‚îÇ¬†¬†     ‚îú‚îÄ‚îÄ pyxplod_write_extracted_file.py
‚îÇ¬†¬†     ‚îî‚îÄ‚îÄ pyxplod.py
‚îú‚îÄ‚îÄ test_unicode.py
‚îú‚îÄ‚îÄ tests
‚îÇ¬†¬† ‚îú‚îÄ‚îÄ __pycache__
‚îÇ¬†¬† ‚îÇ¬†¬† ‚îú‚îÄ‚îÄ test_package.cpython-312-pytest-8.3.5.pyc
‚îÇ¬†¬† ‚îÇ¬†¬† ‚îî‚îÄ‚îÄ test_pyxplod.cpython-312-pytest-8.3.5.pyc
‚îÇ¬†¬† ‚îú‚îÄ‚îÄ test_package.py
‚îÇ¬†¬† ‚îî‚îÄ‚îÄ test_pyxplod.py
‚îî‚îÄ‚îÄ TODO.md

16 directories, 74 files
